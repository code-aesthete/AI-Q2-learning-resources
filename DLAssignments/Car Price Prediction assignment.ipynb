{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Price Prediction::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/hellbuoy/car-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n",
    "\n",
    "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n",
    "\n",
    "Which variables are significant in predicting the price of a car\n",
    "How well those variables describe the price of a car\n",
    "Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n",
    "\n",
    "# task::\n",
    "We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Load Data          ################ DONE\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature ) ############# DONE\n",
    "\n",
    "3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels). # DONE\n",
    "\n",
    "4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
    "\n",
    "6.Train the Model with Epochs (100) and validate it\n",
    "\n",
    "7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "8.Evaluation Step\n",
    "\n",
    "9.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hc\\Documents\\GitHub\\AI-Q2-learning-resources\\DLAssignments\\data\\Car Price Prediction\\CarPrice_Assignment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling                   CarName fueltype aspiration doornumber  \\\n",
       "0       1          3        alfa-romero giulia      gas        std        two   \n",
       "1       2          3       alfa-romero stelvio      gas        std        two   \n",
       "2       3          1  alfa-romero Quadrifoglio      gas        std        two   \n",
       "3       4          2               audi 100 ls      gas        std       four   \n",
       "4       5          2                audi 100ls      gas        std       four   \n",
       "\n",
       "       carbody drivewheel enginelocation  wheelbase  ...  enginesize  \\\n",
       "0  convertible        rwd          front       88.6  ...         130   \n",
       "1  convertible        rwd          front       88.6  ...         130   \n",
       "2    hatchback        rwd          front       94.5  ...         152   \n",
       "3        sedan        fwd          front       99.8  ...         109   \n",
       "4        sedan        4wd          front       99.4  ...         136   \n",
       "\n",
       "   fuelsystem  boreratio  stroke compressionratio horsepower  peakrpm citympg  \\\n",
       "0        mpfi       3.47    2.68              9.0        111     5000      21   \n",
       "1        mpfi       3.47    2.68              9.0        111     5000      21   \n",
       "2        mpfi       2.68    3.47              9.0        154     5000      19   \n",
       "3        mpfi       3.19    3.40             10.0        102     5500      24   \n",
       "4        mpfi       3.19    3.40              8.0        115     5500      18   \n",
       "\n",
       "   highwaympg    price  \n",
       "0          27  13495.0  \n",
       "1          27  16500.0  \n",
       "2          26  16500.0  \n",
       "3          30  13950.0  \n",
       "4          22  17450.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # 205 records, 26 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID              0\n",
       "symboling           0\n",
       "CarName             0\n",
       "fueltype            0\n",
       "aspiration          0\n",
       "doornumber          0\n",
       "carbody             0\n",
       "drivewheel          0\n",
       "enginelocation      0\n",
       "wheelbase           0\n",
       "carlength           0\n",
       "carwidth            0\n",
       "carheight           0\n",
       "curbweight          0\n",
       "enginetype          0\n",
       "cylindernumber      0\n",
       "enginesize          0\n",
       "fuelsystem          0\n",
       "boreratio           0\n",
       "stroke              0\n",
       "compressionratio    0\n",
       "horsepower          0\n",
       "peakrpm             0\n",
       "citympg             0\n",
       "highwaympg          0\n",
       "price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum() # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205 entries, 0 to 204\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   car_ID            205 non-null    int64  \n",
      " 1   symboling         205 non-null    int64  \n",
      " 2   CarName           205 non-null    object \n",
      " 3   fueltype          205 non-null    object \n",
      " 4   aspiration        205 non-null    object \n",
      " 5   doornumber        205 non-null    object \n",
      " 6   carbody           205 non-null    object \n",
      " 7   drivewheel        205 non-null    object \n",
      " 8   enginelocation    205 non-null    object \n",
      " 9   wheelbase         205 non-null    float64\n",
      " 10  carlength         205 non-null    float64\n",
      " 11  carwidth          205 non-null    float64\n",
      " 12  carheight         205 non-null    float64\n",
      " 13  curbweight        205 non-null    int64  \n",
      " 14  enginetype        205 non-null    object \n",
      " 15  cylindernumber    205 non-null    object \n",
      " 16  enginesize        205 non-null    int64  \n",
      " 17  fuelsystem        205 non-null    object \n",
      " 18  boreratio         205 non-null    float64\n",
      " 19  stroke            205 non-null    float64\n",
      " 20  compressionratio  205 non-null    float64\n",
      " 21  horsepower        205 non-null    int64  \n",
      " 22  peakrpm           205 non-null    int64  \n",
      " 23  citympg           205 non-null    int64  \n",
      " 24  highwaympg        205 non-null    int64  \n",
      " 25  price             205 non-null    float64\n",
      "dtypes: float64(8), int64(8), object(10)\n",
      "memory usage: 41.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# cross checking\n",
    "df.info() # no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data has all the data (except car_id, and prediction target i.e. price)\n",
    "# targets has all prediction target records\n",
    "\n",
    "data = df.loc[:, 'symboling':'highwaympg'] # not including Car_ID because it plays no role in predicting price\n",
    "targets = df.loc[:, 'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Shuffling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>...</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>buick electra 225 custom</td>\n",
       "      <td>diesel</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>110.0</td>\n",
       "      <td>190.9</td>\n",
       "      <td>...</td>\n",
       "      <td>five</td>\n",
       "      <td>183</td>\n",
       "      <td>idi</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.640</td>\n",
       "      <td>21.5</td>\n",
       "      <td>123</td>\n",
       "      <td>4350</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nissan rogue</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>165.3</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>97</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.290</td>\n",
       "      <td>9.4</td>\n",
       "      <td>69</td>\n",
       "      <td>5200</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>audi 5000</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>...</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.400</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>mitsubishi outlander</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>96.3</td>\n",
       "      <td>172.4</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>110</td>\n",
       "      <td>spdi</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.460</td>\n",
       "      <td>7.5</td>\n",
       "      <td>116</td>\n",
       "      <td>5500</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>saab 99gle</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.1</td>\n",
       "      <td>186.6</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>121</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.070</td>\n",
       "      <td>9.3</td>\n",
       "      <td>110</td>\n",
       "      <td>5250</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>audi 5000s (diesel)</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.5</td>\n",
       "      <td>178.2</td>\n",
       "      <td>...</td>\n",
       "      <td>five</td>\n",
       "      <td>131</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.400</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160</td>\n",
       "      <td>5500</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3</td>\n",
       "      <td>mazda rx-7 gs</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>95.3</td>\n",
       "      <td>169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>two</td>\n",
       "      <td>70</td>\n",
       "      <td>4bbl</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.255</td>\n",
       "      <td>9.4</td>\n",
       "      <td>101</td>\n",
       "      <td>6000</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>3</td>\n",
       "      <td>nissan kicks</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>91.3</td>\n",
       "      <td>170.7</td>\n",
       "      <td>...</td>\n",
       "      <td>six</td>\n",
       "      <td>181</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.270</td>\n",
       "      <td>7.8</td>\n",
       "      <td>200</td>\n",
       "      <td>5200</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2</td>\n",
       "      <td>volkswagen super beetle</td>\n",
       "      <td>diesel</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>97</td>\n",
       "      <td>idi</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.400</td>\n",
       "      <td>23.0</td>\n",
       "      <td>68</td>\n",
       "      <td>4500</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2</td>\n",
       "      <td>volkswagen 411 (sw)</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.400</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85</td>\n",
       "      <td>5250</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling                   CarName fueltype aspiration doornumber  \\\n",
       "0           -1  buick electra 225 custom   diesel      turbo       four   \n",
       "1            1              nissan rogue      gas        std        two   \n",
       "2            1                 audi 5000      gas        std       four   \n",
       "3            1      mitsubishi outlander      gas      turbo       four   \n",
       "4            2                saab 99gle      gas        std       four   \n",
       "..         ...                       ...      ...        ...        ...   \n",
       "200          0       audi 5000s (diesel)      gas      turbo        two   \n",
       "201          3             mazda rx-7 gs      gas        std        two   \n",
       "202          3              nissan kicks      gas      turbo        two   \n",
       "203          2   volkswagen super beetle   diesel      turbo       four   \n",
       "204          2       volkswagen 411 (sw)      gas        std       four   \n",
       "\n",
       "       carbody drivewheel enginelocation  wheelbase  carlength  ...  \\\n",
       "0        sedan        rwd          front      110.0      190.9  ...   \n",
       "1        sedan        fwd          front       94.5      165.3  ...   \n",
       "2        wagon        fwd          front      105.8      192.7  ...   \n",
       "3        sedan        fwd          front       96.3      172.4  ...   \n",
       "4        sedan        fwd          front       99.1      186.6  ...   \n",
       "..         ...        ...            ...        ...        ...  ...   \n",
       "200  hatchback        4wd          front       99.5      178.2  ...   \n",
       "201  hatchback        rwd          front       95.3      169.0  ...   \n",
       "202  hatchback        rwd          front       91.3      170.7  ...   \n",
       "203      sedan        fwd          front       97.3      171.7  ...   \n",
       "204      sedan        fwd          front       97.3      171.7  ...   \n",
       "\n",
       "     cylindernumber  enginesize  fuelsystem boreratio stroke  \\\n",
       "0              five         183         idi      3.58  3.640   \n",
       "1              four          97        2bbl      3.15  3.290   \n",
       "2              five         136        mpfi      3.19  3.400   \n",
       "3              four         110        spdi      3.17  3.460   \n",
       "4              four         121        mpfi      3.54  3.070   \n",
       "..              ...         ...         ...       ...    ...   \n",
       "200            five         131        mpfi      3.13  3.400   \n",
       "201             two          70        4bbl      3.33  3.255   \n",
       "202             six         181        mpfi      3.43  3.270   \n",
       "203            four          97         idi      3.01  3.400   \n",
       "204            four         109        mpfi      3.19  3.400   \n",
       "\n",
       "     compressionratio horsepower  peakrpm  citympg  highwaympg  \n",
       "0                21.5        123     4350       22          25  \n",
       "1                 9.4         69     5200       31          37  \n",
       "2                 8.5        110     5500       19          25  \n",
       "3                 7.5        116     5500       23          30  \n",
       "4                 9.3        110     5250       21          28  \n",
       "..                ...        ...      ...      ...         ...  \n",
       "200               7.0        160     5500       16          22  \n",
       "201               9.4        101     6000       17          23  \n",
       "202               7.8        200     5200       17          23  \n",
       "203              23.0         68     4500       37          42  \n",
       "204               9.0         85     5250       27          34  \n",
       "\n",
       "[205 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling data\n",
    "# https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True) #  drop = True will prevent adding an index column\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data (Train, Test, Validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data, Targets\n",
      "\n",
      "TRAIN\n",
      "(102, 24)\n",
      "(102,)\n",
      "###############\n",
      "VALIDATION\n",
      "(41, 24)\n",
      "(41,)\n",
      "###############\n",
      "TEST\n",
      "(62, 24)\n",
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "# Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "\n",
    "# 50 + 20 => 70 percent for training and validation NOOOOOOOOOO {this is for k fold validation which isnt the case here}\n",
    "\n",
    "\n",
    "# 50 percent of 205 = 102\n",
    "train_data = data.iloc[:102] ############# 0 based so end at 143 @!%$#&^$&!@$\n",
    "train_targets = targets.iloc[:102]\n",
    "\n",
    "# 20 percent of 205 = 41\n",
    "validation_data = data.iloc[102: 143]\n",
    "validation_targets = targets.iloc[102: 143]\n",
    "\n",
    "# 30 percent for test\n",
    "# 205 - 143 = 62\n",
    "test_data = data.iloc[143:]\n",
    "test_targets = targets.iloc[143:]\n",
    "\n",
    "# cross checking\n",
    "print('Data, Targets', end='\\n\\n')\n",
    "print('TRAIN')\n",
    "print(train_data.shape)\n",
    "print(train_targets.shape)\n",
    "print('#'*15)\n",
    "\n",
    "print('VALIDATION')\n",
    "print(validation_data.shape)\n",
    "print(validation_targets.shape)\n",
    "print('#'*15)\n",
    "\n",
    "print('TEST')\n",
    "print(test_data.shape)\n",
    "print(test_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>...</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>buick electra 225 custom</td>\n",
       "      <td>diesel</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>110.0</td>\n",
       "      <td>190.9</td>\n",
       "      <td>...</td>\n",
       "      <td>five</td>\n",
       "      <td>183</td>\n",
       "      <td>idi</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.64</td>\n",
       "      <td>21.5</td>\n",
       "      <td>123</td>\n",
       "      <td>4350</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nissan rogue</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>165.3</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>97</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.29</td>\n",
       "      <td>9.4</td>\n",
       "      <td>69</td>\n",
       "      <td>5200</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>audi 5000</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>...</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>mitsubishi outlander</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>96.3</td>\n",
       "      <td>172.4</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>110</td>\n",
       "      <td>spdi</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.46</td>\n",
       "      <td>7.5</td>\n",
       "      <td>116</td>\n",
       "      <td>5500</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>saab 99gle</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.1</td>\n",
       "      <td>186.6</td>\n",
       "      <td>...</td>\n",
       "      <td>four</td>\n",
       "      <td>121</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.3</td>\n",
       "      <td>110</td>\n",
       "      <td>5250</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling                   CarName fueltype aspiration doornumber carbody  \\\n",
       "0         -1  buick electra 225 custom   diesel      turbo       four   sedan   \n",
       "1          1              nissan rogue      gas        std        two   sedan   \n",
       "2          1                 audi 5000      gas        std       four   wagon   \n",
       "3          1      mitsubishi outlander      gas      turbo       four   sedan   \n",
       "4          2                saab 99gle      gas        std       four   sedan   \n",
       "\n",
       "  drivewheel enginelocation  wheelbase  carlength  ...  cylindernumber  \\\n",
       "0        rwd          front      110.0      190.9  ...            five   \n",
       "1        fwd          front       94.5      165.3  ...            four   \n",
       "2        fwd          front      105.8      192.7  ...            five   \n",
       "3        fwd          front       96.3      172.4  ...            four   \n",
       "4        fwd          front       99.1      186.6  ...            four   \n",
       "\n",
       "   enginesize  fuelsystem boreratio stroke  compressionratio horsepower  \\\n",
       "0         183         idi      3.58   3.64              21.5        123   \n",
       "1          97        2bbl      3.15   3.29               9.4         69   \n",
       "2         136        mpfi      3.19   3.40               8.5        110   \n",
       "3         110        spdi      3.17   3.46               7.5        116   \n",
       "4         121        mpfi      3.54   3.07               9.3        110   \n",
       "\n",
       "   peakrpm  citympg  highwaympg  \n",
       "0     4350       22          25  \n",
       "1     5200       31          37  \n",
       "2     5500       19          25  \n",
       "3     5500       23          30  \n",
       "4     5250       21          28  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "\n",
    "\n",
    "# finding correaltion wrt training data, if found highly correlated columns, those columns\n",
    "# can be removed from train, test, validate datasets altogehter --- no need to find\n",
    "# correlation for test and validation datasets seperately\n",
    "\n",
    "sns.heatmap(df.corr(method='spearman'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Based on the above heatmap, we can drop symboling, stroke, compressionratio, peakrpm, carheight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlated_cols = ['symboling', 'stroke', 'compressionratio', 'peakrpm', 'carheight']\n",
    "\n",
    "# train_data = train_data.drop(correlated_cols, axis = 'columns')\n",
    "\n",
    "# validation_data = validation_data.drop(correlated_cols, axis = 'columns')\n",
    "\n",
    "# test_data = test_data.drop(correlated_cols, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>buick electra 225 custom</td>\n",
       "      <td>diesel</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>110.0</td>\n",
       "      <td>190.9</td>\n",
       "      <td>70.3</td>\n",
       "      <td>56.5</td>\n",
       "      <td>3515</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>183</td>\n",
       "      <td>idi</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.64</td>\n",
       "      <td>21.5</td>\n",
       "      <td>123</td>\n",
       "      <td>4350</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nissan rogue</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>165.3</td>\n",
       "      <td>63.8</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1918</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>97</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.29</td>\n",
       "      <td>9.4</td>\n",
       "      <td>69</td>\n",
       "      <td>5200</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>audi 5000</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2954</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>mitsubishi outlander</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>96.3</td>\n",
       "      <td>172.4</td>\n",
       "      <td>65.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>2403</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>110</td>\n",
       "      <td>spdi</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.46</td>\n",
       "      <td>7.5</td>\n",
       "      <td>116</td>\n",
       "      <td>5500</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>saab 99gle</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.1</td>\n",
       "      <td>186.6</td>\n",
       "      <td>66.5</td>\n",
       "      <td>56.1</td>\n",
       "      <td>2758</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>121</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.07</td>\n",
       "      <td>9.3</td>\n",
       "      <td>110</td>\n",
       "      <td>5250</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling                   CarName fueltype aspiration doornumber carbody  \\\n",
       "0         -1  buick electra 225 custom   diesel      turbo       four   sedan   \n",
       "1          1              nissan rogue      gas        std        two   sedan   \n",
       "2          1                 audi 5000      gas        std       four   wagon   \n",
       "3          1      mitsubishi outlander      gas      turbo       four   sedan   \n",
       "4          2                saab 99gle      gas        std       four   sedan   \n",
       "\n",
       "  drivewheel enginelocation  wheelbase  carlength  carwidth  carheight  \\\n",
       "0        rwd          front      110.0      190.9      70.3       56.5   \n",
       "1        fwd          front       94.5      165.3      63.8       54.5   \n",
       "2        fwd          front      105.8      192.7      71.4       55.7   \n",
       "3        fwd          front       96.3      172.4      65.4       51.6   \n",
       "4        fwd          front       99.1      186.6      66.5       56.1   \n",
       "\n",
       "   curbweight enginetype cylindernumber  enginesize fuelsystem  boreratio  \\\n",
       "0        3515        ohc           five         183        idi       3.58   \n",
       "1        1918        ohc           four          97       2bbl       3.15   \n",
       "2        2954        ohc           five         136       mpfi       3.19   \n",
       "3        2403        ohc           four         110       spdi       3.17   \n",
       "4        2758        ohc           four         121       mpfi       3.54   \n",
       "\n",
       "   stroke  compressionratio  horsepower  peakrpm  citympg  highwaympg  \n",
       "0    3.64              21.5         123     4350       22          25  \n",
       "1    3.29               9.4          69     5200       31          37  \n",
       "2    3.40               8.5         110     5500       19          25  \n",
       "3    3.46               7.5         116     5500       23          30  \n",
       "4    3.07               9.3         110     5250       21          28  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above plot makes no sense, we can further try by dividing cars according to company instead of model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling             int64\n",
       "CarName              object\n",
       "fueltype             object\n",
       "aspiration           object\n",
       "doornumber           object\n",
       "carbody              object\n",
       "drivewheel           object\n",
       "enginelocation       object\n",
       "wheelbase           float64\n",
       "carlength           float64\n",
       "carwidth            float64\n",
       "carheight           float64\n",
       "curbweight            int64\n",
       "enginetype           object\n",
       "cylindernumber       object\n",
       "enginesize            int64\n",
       "fuelsystem           object\n",
       "boreratio           float64\n",
       "stroke              float64\n",
       "compressionratio    float64\n",
       "horsepower            int64\n",
       "peakrpm               int64\n",
       "citympg               int64\n",
       "highwaympg            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bruteforce solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = ['highwaympg', 'wheelbase', 'carlength', 'carwidth', 'curbweight', 'enginesize', 'boreratio', \n",
    "       'horsepower', 'citympg', 'peakrpm', 'compressionratio', 'carheight', 'stroke']\n",
    "\n",
    "train_data = train_data[filt]\n",
    "validation_data = validation_data[filt]\n",
    "test_data = test_data[filt]\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 \n",
    "# unit & Output Layer \n",
    "# with activation function relu/tanh (check by experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "validation_data-=mean\n",
    "validation_data /= std\n",
    "\n",
    "test_data-=mean\n",
    "test_data /= std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING MODEL\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(13, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(11, activation='relu')) ###\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='relu')) ###\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='relu')) ###\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.shape # 9 features\n",
    "# test_data.shape # 9 features\n",
    "# validation_data.shape # 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 11)                154       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 631\n",
      "Trainable params: 631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILING\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_targets = np.array(train_targets)\n",
    "# validation_targets = np.array(validation_targets)\n",
    "# test_targets = np.array(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.array(train_data)\n",
    "# validation_data = np.array(validation_data)\n",
    "# test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = validation_data\n",
    "val_targets = validation_targets\n",
    "\n",
    "val_data.shape\n",
    "# val_targets.shape\n",
    "# val_targets\n",
    "val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102 samples, validate on 41 samples\n",
      "Epoch 1/1100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 280094368.0000 - mae: 13788.3984 - val_loss: 280448576.0000 - val_mae: 14915.3320\n",
      "Epoch 2/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280093440.0000 - mae: 13788.3594 - val_loss: 280447840.0000 - val_mae: 14915.3105\n",
      "Epoch 3/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280092928.0000 - mae: 13788.3369 - val_loss: 280447456.0000 - val_mae: 14915.2988\n",
      "Epoch 4/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280092640.0000 - mae: 13788.3262 - val_loss: 280447200.0000 - val_mae: 14915.2900\n",
      "Epoch 5/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280092448.0000 - mae: 13788.3174 - val_loss: 280446976.0000 - val_mae: 14915.2832\n",
      "Epoch 6/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280092320.0000 - mae: 13788.3125 - val_loss: 280446816.0000 - val_mae: 14915.2773\n",
      "Epoch 7/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280092192.0000 - mae: 13788.3076 - val_loss: 280446688.0000 - val_mae: 14915.2725\n",
      "Epoch 8/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280092064.0000 - mae: 13788.3027 - val_loss: 280446560.0000 - val_mae: 14915.2686\n",
      "Epoch 9/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280091936.0000 - mae: 13788.2988 - val_loss: 280446432.0000 - val_mae: 14915.2656\n",
      "Epoch 10/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280091872.0000 - mae: 13788.2949 - val_loss: 280446336.0000 - val_mae: 14915.2617\n",
      "Epoch 11/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280091776.0000 - mae: 13788.2920 - val_loss: 280446240.0000 - val_mae: 14915.2578\n",
      "Epoch 12/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280091680.0000 - mae: 13788.2881 - val_loss: 280446112.0000 - val_mae: 14915.2529\n",
      "Epoch 13/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280091552.0000 - mae: 13788.2842 - val_loss: 280445984.0000 - val_mae: 14915.2480\n",
      "Epoch 14/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280091488.0000 - mae: 13788.2793 - val_loss: 280445856.0000 - val_mae: 14915.2471\n",
      "Epoch 15/1100\n",
      "102/102 [==============================] - 0s 108us/step - loss: 280091360.0000 - mae: 13788.2773 - val_loss: 280445728.0000 - val_mae: 14915.2412\n",
      "Epoch 16/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280091264.0000 - mae: 13788.2725 - val_loss: 280445600.0000 - val_mae: 14915.2363\n",
      "Epoch 17/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280091200.0000 - mae: 13788.2686 - val_loss: 280445440.0000 - val_mae: 14915.2305\n",
      "Epoch 18/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280091072.0000 - mae: 13788.2656 - val_loss: 280445280.0000 - val_mae: 14915.2236\n",
      "Epoch 19/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280090944.0000 - mae: 13788.2607 - val_loss: 280445152.0000 - val_mae: 14915.2207\n",
      "Epoch 20/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280090880.0000 - mae: 13788.2559 - val_loss: 280445024.0000 - val_mae: 14915.2168\n",
      "Epoch 21/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280090752.0000 - mae: 13788.2539 - val_loss: 280444864.0000 - val_mae: 14915.2119\n",
      "Epoch 22/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280090656.0000 - mae: 13788.2490 - val_loss: 280444768.0000 - val_mae: 14915.2090\n",
      "Epoch 23/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280090528.0000 - mae: 13788.2422 - val_loss: 280444640.0000 - val_mae: 14915.2041\n",
      "Epoch 24/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280090432.0000 - mae: 13788.2402 - val_loss: 280444512.0000 - val_mae: 14915.1982\n",
      "Epoch 25/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280090272.0000 - mae: 13788.2354 - val_loss: 280444320.0000 - val_mae: 14915.1953\n",
      "Epoch 26/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280090176.0000 - mae: 13788.2305 - val_loss: 280444192.0000 - val_mae: 14915.1904\n",
      "Epoch 27/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280090048.0000 - mae: 13788.2266 - val_loss: 280444064.0000 - val_mae: 14915.1846\n",
      "Epoch 28/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280089920.0000 - mae: 13788.2227 - val_loss: 280443936.0000 - val_mae: 14915.1797\n",
      "Epoch 29/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280089824.0000 - mae: 13788.2178 - val_loss: 280443744.0000 - val_mae: 14915.1738\n",
      "Epoch 30/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280089664.0000 - mae: 13788.2119 - val_loss: 280443584.0000 - val_mae: 14915.1680\n",
      "Epoch 31/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280089504.0000 - mae: 13788.2070 - val_loss: 280443424.0000 - val_mae: 14915.1611\n",
      "Epoch 32/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280089376.0000 - mae: 13788.2021 - val_loss: 280443264.0000 - val_mae: 14915.1572\n",
      "Epoch 33/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280089248.0000 - mae: 13788.1973 - val_loss: 280443072.0000 - val_mae: 14915.1523\n",
      "Epoch 34/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280089088.0000 - mae: 13788.1904 - val_loss: 280442880.0000 - val_mae: 14915.1465\n",
      "Epoch 35/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280088928.0000 - mae: 13788.1846 - val_loss: 280442656.0000 - val_mae: 14915.1387\n",
      "Epoch 36/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280088736.0000 - mae: 13788.1777 - val_loss: 280442496.0000 - val_mae: 14915.1299\n",
      "Epoch 37/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280088576.0000 - mae: 13788.1729 - val_loss: 280442272.0000 - val_mae: 14915.1230\n",
      "Epoch 38/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280088384.0000 - mae: 13788.1650 - val_loss: 280442048.0000 - val_mae: 14915.1172\n",
      "Epoch 39/1100\n",
      "102/102 [==============================] - 0s 118us/step - loss: 280088192.0000 - mae: 13788.1572 - val_loss: 280441856.0000 - val_mae: 14915.1084\n",
      "Epoch 40/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280088000.0000 - mae: 13788.1504 - val_loss: 280441600.0000 - val_mae: 14915.1025\n",
      "Epoch 41/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280087808.0000 - mae: 13788.1436 - val_loss: 280441344.0000 - val_mae: 14915.0947\n",
      "Epoch 42/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280087616.0000 - mae: 13788.1357 - val_loss: 280441088.0000 - val_mae: 14915.0840\n",
      "Epoch 43/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280087392.0000 - mae: 13788.1279 - val_loss: 280440832.0000 - val_mae: 14915.0742\n",
      "Epoch 44/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280087136.0000 - mae: 13788.1191 - val_loss: 280440544.0000 - val_mae: 14915.0674\n",
      "Epoch 45/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280086944.0000 - mae: 13788.1104 - val_loss: 280440288.0000 - val_mae: 14915.0566\n",
      "Epoch 46/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280086656.0000 - mae: 13788.1016 - val_loss: 280439936.0000 - val_mae: 14915.0439\n",
      "Epoch 47/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280086400.0000 - mae: 13788.0908 - val_loss: 280439648.0000 - val_mae: 14915.0352\n",
      "Epoch 48/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280086112.0000 - mae: 13788.0811 - val_loss: 280439296.0000 - val_mae: 14915.0225\n",
      "Epoch 49/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280085824.0000 - mae: 13788.0713 - val_loss: 280438944.0000 - val_mae: 14915.0137\n",
      "Epoch 50/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280085536.0000 - mae: 13788.0596 - val_loss: 280438624.0000 - val_mae: 14915.0020\n",
      "Epoch 51/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280085248.0000 - mae: 13788.0488 - val_loss: 280438240.0000 - val_mae: 14914.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280084960.0000 - mae: 13788.0381 - val_loss: 280437824.0000 - val_mae: 14914.9756\n",
      "Epoch 53/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280084608.0000 - mae: 13788.0244 - val_loss: 280437440.0000 - val_mae: 14914.9639\n",
      "Epoch 54/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280084256.0000 - mae: 13788.0146 - val_loss: 280437056.0000 - val_mae: 14914.9463\n",
      "Epoch 55/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280083936.0000 - mae: 13788.0010 - val_loss: 280436576.0000 - val_mae: 14914.9346\n",
      "Epoch 56/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280083584.0000 - mae: 13787.9873 - val_loss: 280436160.0000 - val_mae: 14914.9189\n",
      "Epoch 57/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280083200.0000 - mae: 13787.9727 - val_loss: 280435712.0000 - val_mae: 14914.9023\n",
      "Epoch 58/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280082816.0000 - mae: 13787.9580 - val_loss: 280435200.0000 - val_mae: 14914.8867\n",
      "Epoch 59/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280082432.0000 - mae: 13787.9434 - val_loss: 280434752.0000 - val_mae: 14914.8721\n",
      "Epoch 60/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280082016.0000 - mae: 13787.9297 - val_loss: 280434240.0000 - val_mae: 14914.8535\n",
      "Epoch 61/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280081600.0000 - mae: 13787.9141 - val_loss: 280433696.0000 - val_mae: 14914.8369\n",
      "Epoch 62/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280081152.0000 - mae: 13787.8984 - val_loss: 280433152.0000 - val_mae: 14914.8184\n",
      "Epoch 63/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280080736.0000 - mae: 13787.8799 - val_loss: 280432576.0000 - val_mae: 14914.8008\n",
      "Epoch 64/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280080256.0000 - mae: 13787.8623 - val_loss: 280432032.0000 - val_mae: 14914.7803\n",
      "Epoch 65/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280079776.0000 - mae: 13787.8467 - val_loss: 280431456.0000 - val_mae: 14914.7607\n",
      "Epoch 66/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280079264.0000 - mae: 13787.8281 - val_loss: 280430816.0000 - val_mae: 14914.7412\n",
      "Epoch 67/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280078752.0000 - mae: 13787.8096 - val_loss: 280430208.0000 - val_mae: 14914.7197\n",
      "Epoch 68/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280078240.0000 - mae: 13787.7891 - val_loss: 280429504.0000 - val_mae: 14914.6982\n",
      "Epoch 69/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280077696.0000 - mae: 13787.7695 - val_loss: 280428832.0000 - val_mae: 14914.6719\n",
      "Epoch 70/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280077152.0000 - mae: 13787.7471 - val_loss: 280428128.0000 - val_mae: 14914.6514\n",
      "Epoch 71/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280076576.0000 - mae: 13787.7275 - val_loss: 280427424.0000 - val_mae: 14914.6270\n",
      "Epoch 72/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280075936.0000 - mae: 13787.7031 - val_loss: 280426656.0000 - val_mae: 14914.6025\n",
      "Epoch 73/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280075360.0000 - mae: 13787.6826 - val_loss: 280425888.0000 - val_mae: 14914.5742\n",
      "Epoch 74/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280074720.0000 - mae: 13787.6582 - val_loss: 280425088.0000 - val_mae: 14914.5508\n",
      "Epoch 75/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280074048.0000 - mae: 13787.6357 - val_loss: 280424288.0000 - val_mae: 14914.5225\n",
      "Epoch 76/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280073408.0000 - mae: 13787.6104 - val_loss: 280423424.0000 - val_mae: 14914.4941\n",
      "Epoch 77/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280072704.0000 - mae: 13787.5830 - val_loss: 280422560.0000 - val_mae: 14914.4648\n",
      "Epoch 78/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280071968.0000 - mae: 13787.5576 - val_loss: 280421664.0000 - val_mae: 14914.4346\n",
      "Epoch 79/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280071264.0000 - mae: 13787.5303 - val_loss: 280420704.0000 - val_mae: 14914.4043\n",
      "Epoch 80/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280070496.0000 - mae: 13787.5010 - val_loss: 280419744.0000 - val_mae: 14914.3730\n",
      "Epoch 81/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 280069696.0000 - mae: 13787.4746 - val_loss: 280418784.0000 - val_mae: 14914.3389\n",
      "Epoch 82/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280068928.0000 - mae: 13787.4424 - val_loss: 280417696.0000 - val_mae: 14914.3037\n",
      "Epoch 83/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280068064.0000 - mae: 13787.4121 - val_loss: 280416640.0000 - val_mae: 14914.2695\n",
      "Epoch 84/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 280067200.0000 - mae: 13787.3799 - val_loss: 280415584.0000 - val_mae: 14914.2344\n",
      "Epoch 85/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280066304.0000 - mae: 13787.3457 - val_loss: 280414464.0000 - val_mae: 14914.1953\n",
      "Epoch 86/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280065408.0000 - mae: 13787.3135 - val_loss: 280413280.0000 - val_mae: 14914.1553\n",
      "Epoch 87/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280064416.0000 - mae: 13787.2783 - val_loss: 280412032.0000 - val_mae: 14914.1162\n",
      "Epoch 88/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280063424.0000 - mae: 13787.2412 - val_loss: 280410784.0000 - val_mae: 14914.0732\n",
      "Epoch 89/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280062400.0000 - mae: 13787.2051 - val_loss: 280409472.0000 - val_mae: 14914.0303\n",
      "Epoch 90/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280061376.0000 - mae: 13787.1641 - val_loss: 280408160.0000 - val_mae: 14913.9844\n",
      "Epoch 91/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280060320.0000 - mae: 13787.1240 - val_loss: 280406784.0000 - val_mae: 14913.9404\n",
      "Epoch 92/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280059232.0000 - mae: 13787.0830 - val_loss: 280405376.0000 - val_mae: 14913.8936\n",
      "Epoch 93/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280058048.0000 - mae: 13787.0400 - val_loss: 280403936.0000 - val_mae: 14913.8457\n",
      "Epoch 94/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280056896.0000 - mae: 13786.9990 - val_loss: 280402432.0000 - val_mae: 14913.7959\n",
      "Epoch 95/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280055712.0000 - mae: 13786.9551 - val_loss: 280400960.0000 - val_mae: 14913.7451\n",
      "Epoch 96/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280054496.0000 - mae: 13786.9092 - val_loss: 280399360.0000 - val_mae: 14913.6953\n",
      "Epoch 97/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280053216.0000 - mae: 13786.8623 - val_loss: 280397760.0000 - val_mae: 14913.6416\n",
      "Epoch 98/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280051904.0000 - mae: 13786.8135 - val_loss: 280396128.0000 - val_mae: 14913.5869\n",
      "Epoch 99/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280050560.0000 - mae: 13786.7646 - val_loss: 280394432.0000 - val_mae: 14913.5303\n",
      "Epoch 100/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280049216.0000 - mae: 13786.7148 - val_loss: 280392672.0000 - val_mae: 14913.4736\n",
      "Epoch 101/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280047808.0000 - mae: 13786.6631 - val_loss: 280390912.0000 - val_mae: 14913.4150\n",
      "Epoch 102/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280046368.0000 - mae: 13786.6094 - val_loss: 280389088.0000 - val_mae: 14913.3555\n",
      "Epoch 103/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280044864.0000 - mae: 13786.5547 - val_loss: 280387200.0000 - val_mae: 14913.2930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280043360.0000 - mae: 13786.4990 - val_loss: 280385280.0000 - val_mae: 14913.2275\n",
      "Epoch 105/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280041824.0000 - mae: 13786.4414 - val_loss: 280383328.0000 - val_mae: 14913.1631\n",
      "Epoch 106/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280040192.0000 - mae: 13786.3828 - val_loss: 280381280.0000 - val_mae: 14913.0947\n",
      "Epoch 107/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280038560.0000 - mae: 13786.3223 - val_loss: 280379232.0000 - val_mae: 14913.0264\n",
      "Epoch 108/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280036864.0000 - mae: 13786.2607 - val_loss: 280377056.0000 - val_mae: 14912.9541\n",
      "Epoch 109/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280035136.0000 - mae: 13786.1963 - val_loss: 280374880.0000 - val_mae: 14912.8809\n",
      "Epoch 110/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280033344.0000 - mae: 13786.1309 - val_loss: 280372608.0000 - val_mae: 14912.8076\n",
      "Epoch 111/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280031520.0000 - mae: 13786.0635 - val_loss: 280370304.0000 - val_mae: 14912.7305\n",
      "Epoch 112/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280029632.0000 - mae: 13785.9941 - val_loss: 280367936.0000 - val_mae: 14912.6514\n",
      "Epoch 113/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280027712.0000 - mae: 13785.9219 - val_loss: 280365504.0000 - val_mae: 14912.5713\n",
      "Epoch 114/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 280025760.0000 - mae: 13785.8516 - val_loss: 280363008.0000 - val_mae: 14912.4883\n",
      "Epoch 115/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280023712.0000 - mae: 13785.7754 - val_loss: 280360480.0000 - val_mae: 14912.4023\n",
      "Epoch 116/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280021664.0000 - mae: 13785.7012 - val_loss: 280357824.0000 - val_mae: 14912.3174\n",
      "Epoch 117/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280019520.0000 - mae: 13785.6221 - val_loss: 280355136.0000 - val_mae: 14912.2236\n",
      "Epoch 118/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280017344.0000 - mae: 13785.5430 - val_loss: 280352384.0000 - val_mae: 14912.1338\n",
      "Epoch 119/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280015104.0000 - mae: 13785.4609 - val_loss: 280349536.0000 - val_mae: 14912.0400\n",
      "Epoch 120/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280012832.0000 - mae: 13785.3760 - val_loss: 280346624.0000 - val_mae: 14911.9434\n",
      "Epoch 121/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280010464.0000 - mae: 13785.2920 - val_loss: 280343680.0000 - val_mae: 14911.8447\n",
      "Epoch 122/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280008064.0000 - mae: 13785.2031 - val_loss: 280340576.0000 - val_mae: 14911.7422\n",
      "Epoch 123/1100\n",
      "102/102 [==============================] - 0s 69us/step - loss: 280005600.0000 - mae: 13785.1123 - val_loss: 280337472.0000 - val_mae: 14911.6406\n",
      "Epoch 124/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 280003072.0000 - mae: 13785.0186 - val_loss: 280334240.0000 - val_mae: 14911.5322\n",
      "Epoch 125/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 280000480.0000 - mae: 13784.9229 - val_loss: 280330944.0000 - val_mae: 14911.4209\n",
      "Epoch 126/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279997824.0000 - mae: 13784.8262 - val_loss: 280327552.0000 - val_mae: 14911.3096\n",
      "Epoch 127/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279995072.0000 - mae: 13784.7256 - val_loss: 280324096.0000 - val_mae: 14911.1953\n",
      "Epoch 128/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279992288.0000 - mae: 13784.6221 - val_loss: 280320480.0000 - val_mae: 14911.0742\n",
      "Epoch 129/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279989376.0000 - mae: 13784.5186 - val_loss: 280316864.0000 - val_mae: 14910.9541\n",
      "Epoch 130/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279986432.0000 - mae: 13784.4092 - val_loss: 280313088.0000 - val_mae: 14910.8291\n",
      "Epoch 131/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279983424.0000 - mae: 13784.2988 - val_loss: 280309248.0000 - val_mae: 14910.7031\n",
      "Epoch 132/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279980320.0000 - mae: 13784.1865 - val_loss: 280305280.0000 - val_mae: 14910.5713\n",
      "Epoch 133/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279977184.0000 - mae: 13784.0713 - val_loss: 280301248.0000 - val_mae: 14910.4395\n",
      "Epoch 134/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279973920.0000 - mae: 13783.9521 - val_loss: 280297120.0000 - val_mae: 14910.3018\n",
      "Epoch 135/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279970624.0000 - mae: 13783.8311 - val_loss: 280292864.0000 - val_mae: 14910.1611\n",
      "Epoch 136/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279967200.0000 - mae: 13783.7061 - val_loss: 280288544.0000 - val_mae: 14910.0166\n",
      "Epoch 137/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279963744.0000 - mae: 13783.5811 - val_loss: 280284096.0000 - val_mae: 14909.8721\n",
      "Epoch 138/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279960192.0000 - mae: 13783.4512 - val_loss: 280279552.0000 - val_mae: 14909.7207\n",
      "Epoch 139/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279956512.0000 - mae: 13783.3164 - val_loss: 280274880.0000 - val_mae: 14909.5654\n",
      "Epoch 140/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279952800.0000 - mae: 13783.1787 - val_loss: 280270112.0000 - val_mae: 14909.4082\n",
      "Epoch 141/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279948960.0000 - mae: 13783.0400 - val_loss: 280265216.0000 - val_mae: 14909.2471\n",
      "Epoch 142/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279945056.0000 - mae: 13782.8975 - val_loss: 280260256.0000 - val_mae: 14909.0820\n",
      "Epoch 143/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279941056.0000 - mae: 13782.7490 - val_loss: 280255104.0000 - val_mae: 14908.9111\n",
      "Epoch 144/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279936928.0000 - mae: 13782.6006 - val_loss: 280249856.0000 - val_mae: 14908.7383\n",
      "Epoch 145/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279932736.0000 - mae: 13782.4463 - val_loss: 280244512.0000 - val_mae: 14908.5605\n",
      "Epoch 146/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279928480.0000 - mae: 13782.2891 - val_loss: 280239008.0000 - val_mae: 14908.3779\n",
      "Epoch 147/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279924064.0000 - mae: 13782.1299 - val_loss: 280233408.0000 - val_mae: 14908.1924\n",
      "Epoch 148/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 279919616.0000 - mae: 13781.9658 - val_loss: 280227680.0000 - val_mae: 14908.0020\n",
      "Epoch 149/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279915008.0000 - mae: 13781.7969 - val_loss: 280221792.0000 - val_mae: 14907.8066\n",
      "Epoch 150/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279910304.0000 - mae: 13781.6260 - val_loss: 280215744.0000 - val_mae: 14907.6084\n",
      "Epoch 151/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279905536.0000 - mae: 13781.4502 - val_loss: 280209600.0000 - val_mae: 14907.4043\n",
      "Epoch 152/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279900608.0000 - mae: 13781.2725 - val_loss: 280203328.0000 - val_mae: 14907.1953\n",
      "Epoch 153/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279895616.0000 - mae: 13781.0879 - val_loss: 280196960.0000 - val_mae: 14906.9814\n",
      "Epoch 154/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279890464.0000 - mae: 13780.9023 - val_loss: 280190368.0000 - val_mae: 14906.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279885248.0000 - mae: 13780.7100 - val_loss: 280183648.0000 - val_mae: 14906.5410\n",
      "Epoch 156/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279879936.0000 - mae: 13780.5146 - val_loss: 280176800.0000 - val_mae: 14906.3145\n",
      "Epoch 157/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279874464.0000 - mae: 13780.3154 - val_loss: 280169760.0000 - val_mae: 14906.0840\n",
      "Epoch 158/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279868864.0000 - mae: 13780.1104 - val_loss: 280162624.0000 - val_mae: 14905.8447\n",
      "Epoch 159/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279863168.0000 - mae: 13779.9033 - val_loss: 280155296.0000 - val_mae: 14905.6035\n",
      "Epoch 160/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279857344.0000 - mae: 13779.6885 - val_loss: 280147808.0000 - val_mae: 14905.3535\n",
      "Epoch 161/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279851360.0000 - mae: 13779.4707 - val_loss: 280140160.0000 - val_mae: 14905.0986\n",
      "Epoch 162/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279845280.0000 - mae: 13779.2471 - val_loss: 280132352.0000 - val_mae: 14904.8398\n",
      "Epoch 163/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279839040.0000 - mae: 13779.0225 - val_loss: 280124352.0000 - val_mae: 14904.5742\n",
      "Epoch 164/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279832672.0000 - mae: 13778.7891 - val_loss: 280116224.0000 - val_mae: 14904.3047\n",
      "Epoch 165/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279826208.0000 - mae: 13778.5527 - val_loss: 280107904.0000 - val_mae: 14904.0303\n",
      "Epoch 166/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279819584.0000 - mae: 13778.3115 - val_loss: 280099392.0000 - val_mae: 14903.7471\n",
      "Epoch 167/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279812832.0000 - mae: 13778.0654 - val_loss: 280090688.0000 - val_mae: 14903.4600\n",
      "Epoch 168/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279805920.0000 - mae: 13777.8115 - val_loss: 280081824.0000 - val_mae: 14903.1650\n",
      "Epoch 169/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279798880.0000 - mae: 13777.5566 - val_loss: 280072736.0000 - val_mae: 14902.8662\n",
      "Epoch 170/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279791712.0000 - mae: 13777.2930 - val_loss: 280063488.0000 - val_mae: 14902.5576\n",
      "Epoch 171/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279784352.0000 - mae: 13777.0254 - val_loss: 280054080.0000 - val_mae: 14902.2441\n",
      "Epoch 172/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279776864.0000 - mae: 13776.7510 - val_loss: 280044416.0000 - val_mae: 14901.9238\n",
      "Epoch 173/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279769248.0000 - mae: 13776.4727 - val_loss: 280034592.0000 - val_mae: 14901.5986\n",
      "Epoch 174/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279761440.0000 - mae: 13776.1904 - val_loss: 280024544.0000 - val_mae: 14901.2637\n",
      "Epoch 175/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279753472.0000 - mae: 13775.8975 - val_loss: 280014240.0000 - val_mae: 14900.9238\n",
      "Epoch 176/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279745344.0000 - mae: 13775.6006 - val_loss: 280003840.0000 - val_mae: 14900.5781\n",
      "Epoch 177/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279737056.0000 - mae: 13775.2988 - val_loss: 279993152.0000 - val_mae: 14900.2227\n",
      "Epoch 178/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279728608.0000 - mae: 13774.9912 - val_loss: 279982272.0000 - val_mae: 14899.8613\n",
      "Epoch 179/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279719968.0000 - mae: 13774.6738 - val_loss: 279971104.0000 - val_mae: 14899.4922\n",
      "Epoch 180/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279711168.0000 - mae: 13774.3525 - val_loss: 279959744.0000 - val_mae: 14899.1143\n",
      "Epoch 181/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279702144.0000 - mae: 13774.0254 - val_loss: 279948160.0000 - val_mae: 14898.7305\n",
      "Epoch 182/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279692992.0000 - mae: 13773.6904 - val_loss: 279936288.0000 - val_mae: 14898.3340\n",
      "Epoch 183/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279683616.0000 - mae: 13773.3467 - val_loss: 279924224.0000 - val_mae: 14897.9326\n",
      "Epoch 184/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279674048.0000 - mae: 13772.9971 - val_loss: 279911840.0000 - val_mae: 14897.5215\n",
      "Epoch 185/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279664224.0000 - mae: 13772.6396 - val_loss: 279899264.0000 - val_mae: 14897.1025\n",
      "Epoch 186/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279654240.0000 - mae: 13772.2754 - val_loss: 279886432.0000 - val_mae: 14896.6768\n",
      "Epoch 187/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279644032.0000 - mae: 13771.9033 - val_loss: 279873280.0000 - val_mae: 14896.2393\n",
      "Epoch 188/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279633664.0000 - mae: 13771.5244 - val_loss: 279859904.0000 - val_mae: 14895.7939\n",
      "Epoch 189/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279623072.0000 - mae: 13771.1377 - val_loss: 279846272.0000 - val_mae: 14895.3418\n",
      "Epoch 190/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279612256.0000 - mae: 13770.7441 - val_loss: 279832384.0000 - val_mae: 14894.8770\n",
      "Epoch 191/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279601248.0000 - mae: 13770.3408 - val_loss: 279818176.0000 - val_mae: 14894.4053\n",
      "Epoch 192/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279590016.0000 - mae: 13769.9326 - val_loss: 279803744.0000 - val_mae: 14893.9258\n",
      "Epoch 193/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279578528.0000 - mae: 13769.5156 - val_loss: 279788960.0000 - val_mae: 14893.4346\n",
      "Epoch 194/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279566880.0000 - mae: 13769.0898 - val_loss: 279773920.0000 - val_mae: 14892.9346\n",
      "Epoch 195/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279554944.0000 - mae: 13768.6553 - val_loss: 279758560.0000 - val_mae: 14892.4219\n",
      "Epoch 196/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279542752.0000 - mae: 13768.2119 - val_loss: 279742880.0000 - val_mae: 14891.9043\n",
      "Epoch 197/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279530336.0000 - mae: 13767.7598 - val_loss: 279726944.0000 - val_mae: 14891.3730\n",
      "Epoch 198/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279517696.0000 - mae: 13767.3018 - val_loss: 279710656.0000 - val_mae: 14890.8320\n",
      "Epoch 199/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279504800.0000 - mae: 13766.8320 - val_loss: 279694080.0000 - val_mae: 14890.2803\n",
      "Epoch 200/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279491680.0000 - mae: 13766.3525 - val_loss: 279677184.0000 - val_mae: 14889.7178\n",
      "Epoch 201/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279478240.0000 - mae: 13765.8662 - val_loss: 279659904.0000 - val_mae: 14889.1465\n",
      "Epoch 202/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279464608.0000 - mae: 13765.3701 - val_loss: 279642368.0000 - val_mae: 14888.5605\n",
      "Epoch 203/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279450656.0000 - mae: 13764.8643 - val_loss: 279624416.0000 - val_mae: 14887.9668\n",
      "Epoch 204/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279436416.0000 - mae: 13764.3467 - val_loss: 279606176.0000 - val_mae: 14887.3564\n",
      "Epoch 205/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279421920.0000 - mae: 13763.8213 - val_loss: 279587584.0000 - val_mae: 14886.7363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279407200.0000 - mae: 13763.2842 - val_loss: 279568608.0000 - val_mae: 14886.1055\n",
      "Epoch 207/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279392128.0000 - mae: 13762.7373 - val_loss: 279549312.0000 - val_mae: 14885.4639\n",
      "Epoch 208/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279376768.0000 - mae: 13762.1797 - val_loss: 279529632.0000 - val_mae: 14884.8066\n",
      "Epoch 209/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279361088.0000 - mae: 13761.6123 - val_loss: 279509600.0000 - val_mae: 14884.1387\n",
      "Epoch 210/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279345184.0000 - mae: 13761.0342 - val_loss: 279489184.0000 - val_mae: 14883.4570\n",
      "Epoch 211/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279328928.0000 - mae: 13760.4453 - val_loss: 279468320.0000 - val_mae: 14882.7656\n",
      "Epoch 212/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279312384.0000 - mae: 13759.8428 - val_loss: 279447104.0000 - val_mae: 14882.0596\n",
      "Epoch 213/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279295552.0000 - mae: 13759.2324 - val_loss: 279425472.0000 - val_mae: 14881.3369\n",
      "Epoch 214/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279278432.0000 - mae: 13758.6104 - val_loss: 279403360.0000 - val_mae: 14880.6035\n",
      "Epoch 215/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279260928.0000 - mae: 13757.9746 - val_loss: 279380832.0000 - val_mae: 14879.8535\n",
      "Epoch 216/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279243136.0000 - mae: 13757.3281 - val_loss: 279357952.0000 - val_mae: 14879.0918\n",
      "Epoch 217/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279224960.0000 - mae: 13756.6689 - val_loss: 279334592.0000 - val_mae: 14878.3154\n",
      "Epoch 218/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279206496.0000 - mae: 13755.9990 - val_loss: 279310848.0000 - val_mae: 14877.5264\n",
      "Epoch 219/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279187712.0000 - mae: 13755.3174 - val_loss: 279286720.0000 - val_mae: 14876.7207\n",
      "Epoch 220/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279168544.0000 - mae: 13754.6221 - val_loss: 279262112.0000 - val_mae: 14875.9023\n",
      "Epoch 221/1100\n",
      "102/102 [==============================] - 0s 59us/step - loss: 279149056.0000 - mae: 13753.9150 - val_loss: 279236992.0000 - val_mae: 14875.0654\n",
      "Epoch 222/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279129216.0000 - mae: 13753.1953 - val_loss: 279211424.0000 - val_mae: 14874.2119\n",
      "Epoch 223/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279109024.0000 - mae: 13752.4580 - val_loss: 279185376.0000 - val_mae: 14873.3428\n",
      "Epoch 224/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 279088480.0000 - mae: 13751.7129 - val_loss: 279158848.0000 - val_mae: 14872.4590\n",
      "Epoch 225/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279067520.0000 - mae: 13750.9521 - val_loss: 279131840.0000 - val_mae: 14871.5596\n",
      "Epoch 226/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279046240.0000 - mae: 13750.1787 - val_loss: 279104352.0000 - val_mae: 14870.6416\n",
      "Epoch 227/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 279024544.0000 - mae: 13749.3887 - val_loss: 279076352.0000 - val_mae: 14869.7070\n",
      "Epoch 228/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 279002464.0000 - mae: 13748.5869 - val_loss: 279047840.0000 - val_mae: 14868.7559\n",
      "Epoch 229/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278980000.0000 - mae: 13747.7705 - val_loss: 279018784.0000 - val_mae: 14867.7881\n",
      "Epoch 230/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278957120.0000 - mae: 13746.9404 - val_loss: 278989216.0000 - val_mae: 14866.8008\n",
      "Epoch 231/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278933856.0000 - mae: 13746.0918 - val_loss: 278959200.0000 - val_mae: 14865.7969\n",
      "Epoch 232/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278910176.0000 - mae: 13745.2305 - val_loss: 278928576.0000 - val_mae: 14864.7773\n",
      "Epoch 233/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278886048.0000 - mae: 13744.3545 - val_loss: 278897440.0000 - val_mae: 14863.7383\n",
      "Epoch 234/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278861568.0000 - mae: 13743.4619 - val_loss: 278865760.0000 - val_mae: 14862.6816\n",
      "Epoch 235/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278836640.0000 - mae: 13742.5547 - val_loss: 278833536.0000 - val_mae: 14861.6055\n",
      "Epoch 236/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278811232.0000 - mae: 13741.6309 - val_loss: 278800768.0000 - val_mae: 14860.5107\n",
      "Epoch 237/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278785440.0000 - mae: 13740.6924 - val_loss: 278767456.0000 - val_mae: 14859.3994\n",
      "Epoch 238/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278759168.0000 - mae: 13739.7393 - val_loss: 278733568.0000 - val_mae: 14858.2686\n",
      "Epoch 239/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278732544.0000 - mae: 13738.7676 - val_loss: 278699104.0000 - val_mae: 14857.1172\n",
      "Epoch 240/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278705440.0000 - mae: 13737.7803 - val_loss: 278664064.0000 - val_mae: 14855.9482\n",
      "Epoch 241/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278677856.0000 - mae: 13736.7773 - val_loss: 278628448.0000 - val_mae: 14854.7578\n",
      "Epoch 242/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 278649824.0000 - mae: 13735.7559 - val_loss: 278592224.0000 - val_mae: 14853.5459\n",
      "Epoch 243/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278621312.0000 - mae: 13734.7178 - val_loss: 278555328.0000 - val_mae: 14852.3154\n",
      "Epoch 244/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278592320.0000 - mae: 13733.6641 - val_loss: 278517856.0000 - val_mae: 14851.0625\n",
      "Epoch 245/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278562880.0000 - mae: 13732.5918 - val_loss: 278479808.0000 - val_mae: 14849.7900\n",
      "Epoch 246/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 278532928.0000 - mae: 13731.5029 - val_loss: 278441056.0000 - val_mae: 14848.4941\n",
      "Epoch 247/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278502496.0000 - mae: 13730.3945 - val_loss: 278401664.0000 - val_mae: 14847.1768\n",
      "Epoch 248/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278471520.0000 - mae: 13729.2676 - val_loss: 278361632.0000 - val_mae: 14845.8389\n",
      "Epoch 249/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278440032.0000 - mae: 13728.1221 - val_loss: 278320928.0000 - val_mae: 14844.4756\n",
      "Epoch 250/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278408064.0000 - mae: 13726.9580 - val_loss: 278279552.0000 - val_mae: 14843.0918\n",
      "Epoch 251/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278375552.0000 - mae: 13725.7744 - val_loss: 278237472.0000 - val_mae: 14841.6826\n",
      "Epoch 252/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278342464.0000 - mae: 13724.5703 - val_loss: 278194656.0000 - val_mae: 14840.2471\n",
      "Epoch 253/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278308832.0000 - mae: 13723.3447 - val_loss: 278151136.0000 - val_mae: 14838.7910\n",
      "Epoch 254/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278274688.0000 - mae: 13722.0996 - val_loss: 278106944.0000 - val_mae: 14837.3105\n",
      "Epoch 255/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278239968.0000 - mae: 13720.8350 - val_loss: 278062016.0000 - val_mae: 14835.8066\n",
      "Epoch 256/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278204640.0000 - mae: 13719.5469 - val_loss: 278016384.0000 - val_mae: 14834.2764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1100\n",
      "102/102 [==============================] - 0s 108us/step - loss: 278168768.0000 - mae: 13718.2363 - val_loss: 277970016.0000 - val_mae: 14832.7207\n",
      "Epoch 258/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278132256.0000 - mae: 13716.9082 - val_loss: 277922880.0000 - val_mae: 14831.1406\n",
      "Epoch 259/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278095200.0000 - mae: 13715.5566 - val_loss: 277874976.0000 - val_mae: 14829.5352\n",
      "Epoch 260/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 278057568.0000 - mae: 13714.1836 - val_loss: 277826272.0000 - val_mae: 14827.9023\n",
      "Epoch 261/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 278019360.0000 - mae: 13712.7891 - val_loss: 277776832.0000 - val_mae: 14826.2441\n",
      "Epoch 262/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277980512.0000 - mae: 13711.3711 - val_loss: 277726560.0000 - val_mae: 14824.5605\n",
      "Epoch 263/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277941024.0000 - mae: 13709.9316 - val_loss: 277675520.0000 - val_mae: 14822.8486\n",
      "Epoch 264/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277900960.0000 - mae: 13708.4697 - val_loss: 277623712.0000 - val_mae: 14821.1094\n",
      "Epoch 265/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277860256.0000 - mae: 13706.9844 - val_loss: 277571072.0000 - val_mae: 14819.3428\n",
      "Epoch 266/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277818944.0000 - mae: 13705.4756 - val_loss: 277517600.0000 - val_mae: 14817.5488\n",
      "Epoch 267/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277776960.0000 - mae: 13703.9424 - val_loss: 277463296.0000 - val_mae: 14815.7275\n",
      "Epoch 268/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277734368.0000 - mae: 13702.3877 - val_loss: 277408192.0000 - val_mae: 14813.8750\n",
      "Epoch 269/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277691104.0000 - mae: 13700.8076 - val_loss: 277352192.0000 - val_mae: 14811.9971\n",
      "Epoch 270/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277647136.0000 - mae: 13699.2012 - val_loss: 277295328.0000 - val_mae: 14810.0889\n",
      "Epoch 271/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277602528.0000 - mae: 13697.5713 - val_loss: 277237568.0000 - val_mae: 14808.1475\n",
      "Epoch 272/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277557184.0000 - mae: 13695.9170 - val_loss: 277178944.0000 - val_mae: 14806.1787\n",
      "Epoch 273/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277511200.0000 - mae: 13694.2354 - val_loss: 277119392.0000 - val_mae: 14804.1787\n",
      "Epoch 274/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277464480.0000 - mae: 13692.5273 - val_loss: 277058944.0000 - val_mae: 14802.1475\n",
      "Epoch 275/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277417088.0000 - mae: 13690.7939 - val_loss: 276997568.0000 - val_mae: 14800.0850\n",
      "Epoch 276/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 277368928.0000 - mae: 13689.0342 - val_loss: 276935264.0000 - val_mae: 14797.9912\n",
      "Epoch 277/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 277320032.0000 - mae: 13687.2461 - val_loss: 276872032.0000 - val_mae: 14795.8633\n",
      "Epoch 278/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277270464.0000 - mae: 13685.4326 - val_loss: 276807808.0000 - val_mae: 14793.7061\n",
      "Epoch 279/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277220128.0000 - mae: 13683.5918 - val_loss: 276742624.0000 - val_mae: 14791.5156\n",
      "Epoch 280/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277169024.0000 - mae: 13681.7217 - val_loss: 276676480.0000 - val_mae: 14789.2881\n",
      "Epoch 281/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277117184.0000 - mae: 13679.8252 - val_loss: 276609312.0000 - val_mae: 14787.0293\n",
      "Epoch 282/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 277064544.0000 - mae: 13677.8984 - val_loss: 276541152.0000 - val_mae: 14784.7334\n",
      "Epoch 283/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 277011136.0000 - mae: 13675.9434 - val_loss: 276471968.0000 - val_mae: 14782.4043\n",
      "Epoch 284/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 276956928.0000 - mae: 13673.9580 - val_loss: 276401760.0000 - val_mae: 14780.0381\n",
      "Epoch 285/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 276901920.0000 - mae: 13671.9463 - val_loss: 276330496.0000 - val_mae: 14777.6406\n",
      "Epoch 286/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276846112.0000 - mae: 13669.9023 - val_loss: 276258144.0000 - val_mae: 14775.2012\n",
      "Epoch 287/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 276789408.0000 - mae: 13667.8223 - val_loss: 276184736.0000 - val_mae: 14772.7256\n",
      "Epoch 288/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276731872.0000 - mae: 13665.7129 - val_loss: 276110208.0000 - val_mae: 14770.2139\n",
      "Epoch 289/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276673440.0000 - mae: 13663.5723 - val_loss: 276034592.0000 - val_mae: 14767.6650\n",
      "Epoch 290/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 276614176.0000 - mae: 13661.3994 - val_loss: 275957888.0000 - val_mae: 14765.0762\n",
      "Epoch 291/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 276554016.0000 - mae: 13659.1953 - val_loss: 275880000.0000 - val_mae: 14762.4512\n",
      "Epoch 292/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276493024.0000 - mae: 13656.9570 - val_loss: 275801056.0000 - val_mae: 14759.7852\n",
      "Epoch 293/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276431136.0000 - mae: 13654.6836 - val_loss: 275720992.0000 - val_mae: 14757.0840\n",
      "Epoch 294/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276368320.0000 - mae: 13652.3828 - val_loss: 275639744.0000 - val_mae: 14754.3418\n",
      "Epoch 295/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 276304640.0000 - mae: 13650.0439 - val_loss: 275557376.0000 - val_mae: 14751.5596\n",
      "Epoch 296/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276240032.0000 - mae: 13647.6719 - val_loss: 275473792.0000 - val_mae: 14748.7344\n",
      "Epoch 297/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 276174432.0000 - mae: 13645.2637 - val_loss: 275389024.0000 - val_mae: 14745.8721\n",
      "Epoch 298/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 276107936.0000 - mae: 13642.8213 - val_loss: 275303040.0000 - val_mae: 14742.9668\n",
      "Epoch 299/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 276040544.0000 - mae: 13640.3467 - val_loss: 275215872.0000 - val_mae: 14740.0186\n",
      "Epoch 300/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275972192.0000 - mae: 13637.8330 - val_loss: 275127424.0000 - val_mae: 14737.0303\n",
      "Epoch 301/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 275902816.0000 - mae: 13635.2852 - val_loss: 275037792.0000 - val_mae: 14733.9971\n",
      "Epoch 302/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 275832544.0000 - mae: 13632.7012 - val_loss: 274946816.0000 - val_mae: 14730.9189\n",
      "Epoch 303/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275761248.0000 - mae: 13630.0811 - val_loss: 274854592.0000 - val_mae: 14727.7969\n",
      "Epoch 304/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275688896.0000 - mae: 13627.4199 - val_loss: 274761056.0000 - val_mae: 14724.6309\n",
      "Epoch 305/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 275615552.0000 - mae: 13624.7246 - val_loss: 274666208.0000 - val_mae: 14721.4189\n",
      "Epoch 306/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275541184.0000 - mae: 13621.9893 - val_loss: 274570048.0000 - val_mae: 14718.1631\n",
      "Epoch 307/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275465792.0000 - mae: 13619.2148 - val_loss: 274472576.0000 - val_mae: 14714.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275389344.0000 - mae: 13616.4023 - val_loss: 274373760.0000 - val_mae: 14711.5107\n",
      "Epoch 309/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275311808.0000 - mae: 13613.5488 - val_loss: 274273472.0000 - val_mae: 14708.1143\n",
      "Epoch 310/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 275233248.0000 - mae: 13610.6553 - val_loss: 274171840.0000 - val_mae: 14704.6660\n",
      "Epoch 311/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 275153632.0000 - mae: 13607.7246 - val_loss: 274068832.0000 - val_mae: 14701.1738\n",
      "Epoch 312/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 275072896.0000 - mae: 13604.7500 - val_loss: 273964320.0000 - val_mae: 14697.6309\n",
      "Epoch 313/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 274991072.0000 - mae: 13601.7354 - val_loss: 273858496.0000 - val_mae: 14694.0400\n",
      "Epoch 314/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274908160.0000 - mae: 13598.6787 - val_loss: 273751200.0000 - val_mae: 14690.3965\n",
      "Epoch 315/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274824128.0000 - mae: 13595.5801 - val_loss: 273642432.0000 - val_mae: 14686.7061\n",
      "Epoch 316/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274738944.0000 - mae: 13592.4385 - val_loss: 273532192.0000 - val_mae: 14682.9600\n",
      "Epoch 317/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274652608.0000 - mae: 13589.2549 - val_loss: 273420416.0000 - val_mae: 14679.1650\n",
      "Epoch 318/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274565184.0000 - mae: 13586.0273 - val_loss: 273307136.0000 - val_mae: 14675.3145\n",
      "Epoch 319/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 274476544.0000 - mae: 13582.7539 - val_loss: 273192320.0000 - val_mae: 14671.4102\n",
      "Epoch 320/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 274386720.0000 - mae: 13579.4375 - val_loss: 273075968.0000 - val_mae: 14667.4541\n",
      "Epoch 321/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274295712.0000 - mae: 13576.0762 - val_loss: 272958080.0000 - val_mae: 14663.4424\n",
      "Epoch 322/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274203520.0000 - mae: 13572.6680 - val_loss: 272838592.0000 - val_mae: 14659.3779\n",
      "Epoch 323/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274110080.0000 - mae: 13569.2148 - val_loss: 272717600.0000 - val_mae: 14655.2559\n",
      "Epoch 324/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 274015424.0000 - mae: 13565.7148 - val_loss: 272594816.0000 - val_mae: 14651.0742\n",
      "Epoch 325/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 273919424.0000 - mae: 13562.1650 - val_loss: 272470464.0000 - val_mae: 14646.8350\n",
      "Epoch 326/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 273822208.0000 - mae: 13558.5684 - val_loss: 272344512.0000 - val_mae: 14642.5410\n",
      "Epoch 327/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 273723680.0000 - mae: 13554.9238 - val_loss: 272216928.0000 - val_mae: 14638.1924\n",
      "Epoch 328/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 273623936.0000 - mae: 13551.2305 - val_loss: 272087712.0000 - val_mae: 14633.7832\n",
      "Epoch 329/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 273522880.0000 - mae: 13547.4873 - val_loss: 271956832.0000 - val_mae: 14629.3154\n",
      "Epoch 330/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 273420512.0000 - mae: 13543.6953 - val_loss: 271824224.0000 - val_mae: 14624.7881\n",
      "Epoch 331/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 273316832.0000 - mae: 13539.8545 - val_loss: 271689920.0000 - val_mae: 14620.1992\n",
      "Epoch 332/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 273211840.0000 - mae: 13535.9609 - val_loss: 271553888.0000 - val_mae: 14615.5518\n",
      "Epoch 333/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 273105472.0000 - mae: 13532.0176 - val_loss: 271416160.0000 - val_mae: 14610.8447\n",
      "Epoch 334/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272997792.0000 - mae: 13528.0225 - val_loss: 271276608.0000 - val_mae: 14606.0732\n",
      "Epoch 335/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272888704.0000 - mae: 13523.9727 - val_loss: 271135296.0000 - val_mae: 14601.2383\n",
      "Epoch 336/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272778208.0000 - mae: 13519.8701 - val_loss: 270992192.0000 - val_mae: 14596.3389\n",
      "Epoch 337/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272666368.0000 - mae: 13515.7168 - val_loss: 270847296.0000 - val_mae: 14591.3770\n",
      "Epoch 338/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 272553088.0000 - mae: 13511.5059 - val_loss: 270700544.0000 - val_mae: 14586.3506\n",
      "Epoch 339/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 272438400.0000 - mae: 13507.2412 - val_loss: 270551936.0000 - val_mae: 14581.2559\n",
      "Epoch 340/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272322272.0000 - mae: 13502.9229 - val_loss: 270401472.0000 - val_mae: 14576.0977\n",
      "Epoch 341/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272204672.0000 - mae: 13498.5479 - val_loss: 270249120.0000 - val_mae: 14570.8701\n",
      "Epoch 342/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 272085600.0000 - mae: 13494.1152 - val_loss: 270094752.0000 - val_mae: 14565.5732\n",
      "Epoch 343/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 271965088.0000 - mae: 13489.6279 - val_loss: 269938400.0000 - val_mae: 14560.2041\n",
      "Epoch 344/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 271843040.0000 - mae: 13485.0811 - val_loss: 269780128.0000 - val_mae: 14554.7666\n",
      "Epoch 345/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 271719456.0000 - mae: 13480.4775 - val_loss: 269619904.0000 - val_mae: 14549.2588\n",
      "Epoch 346/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 271594368.0000 - mae: 13475.8135 - val_loss: 269457664.0000 - val_mae: 14543.6797\n",
      "Epoch 347/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 271467648.0000 - mae: 13471.0859 - val_loss: 269293376.0000 - val_mae: 14538.0293\n",
      "Epoch 348/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 271339360.0000 - mae: 13466.2979 - val_loss: 269127072.0000 - val_mae: 14532.3037\n",
      "Epoch 349/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 271209536.0000 - mae: 13461.4502 - val_loss: 268958688.0000 - val_mae: 14526.5059\n",
      "Epoch 350/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 271078112.0000 - mae: 13456.5400 - val_loss: 268788224.0000 - val_mae: 14520.6338\n",
      "Epoch 351/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 270945056.0000 - mae: 13451.5703 - val_loss: 268615776.0000 - val_mae: 14514.6875\n",
      "Epoch 352/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 270810464.0000 - mae: 13446.5371 - val_loss: 268441184.0000 - val_mae: 14508.6650\n",
      "Epoch 353/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 270674208.0000 - mae: 13441.4404 - val_loss: 268264496.0000 - val_mae: 14502.5684\n",
      "Epoch 354/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 270536352.0000 - mae: 13436.2783 - val_loss: 268085648.0000 - val_mae: 14496.3936\n",
      "Epoch 355/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 270396768.0000 - mae: 13431.0518 - val_loss: 267904656.0000 - val_mae: 14490.1406\n",
      "Epoch 356/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 270255552.0000 - mae: 13425.7598 - val_loss: 267721472.0000 - val_mae: 14483.8076\n",
      "Epoch 357/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 270112576.0000 - mae: 13420.4023 - val_loss: 267536128.0000 - val_mae: 14477.3975\n",
      "Epoch 358/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 269967936.0000 - mae: 13414.9756 - val_loss: 267348560.0000 - val_mae: 14470.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 269821568.0000 - mae: 13409.4814 - val_loss: 267158784.0000 - val_mae: 14464.3340\n",
      "Epoch 360/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 269673504.0000 - mae: 13403.9189 - val_loss: 266966784.0000 - val_mae: 14457.6816\n",
      "Epoch 361/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 269523616.0000 - mae: 13398.2891 - val_loss: 266772448.0000 - val_mae: 14450.9453\n",
      "Epoch 362/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 269372032.0000 - mae: 13392.5908 - val_loss: 266575920.0000 - val_mae: 14444.1250\n",
      "Epoch 363/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 269218688.0000 - mae: 13386.8213 - val_loss: 266377040.0000 - val_mae: 14437.2236\n",
      "Epoch 364/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 269063520.0000 - mae: 13380.9805 - val_loss: 266175856.0000 - val_mae: 14430.2344\n",
      "Epoch 365/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 268906560.0000 - mae: 13375.0674 - val_loss: 265972304.0000 - val_mae: 14423.1602\n",
      "Epoch 366/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 268747776.0000 - mae: 13369.0859 - val_loss: 265766416.0000 - val_mae: 14415.9980\n",
      "Epoch 367/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 268587136.0000 - mae: 13363.0283 - val_loss: 265558160.0000 - val_mae: 14408.7520\n",
      "Epoch 368/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 268424688.0000 - mae: 13356.8984 - val_loss: 265347472.0000 - val_mae: 14401.4150\n",
      "Epoch 369/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 268260368.0000 - mae: 13350.6953 - val_loss: 265134384.0000 - val_mae: 14393.9883\n",
      "Epoch 370/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 268094144.0000 - mae: 13344.4150 - val_loss: 264918848.0000 - val_mae: 14386.4707\n",
      "Epoch 371/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 267926048.0000 - mae: 13338.0596 - val_loss: 264700832.0000 - val_mae: 14378.8643\n",
      "Epoch 372/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 267755984.0000 - mae: 13331.6279 - val_loss: 264480336.0000 - val_mae: 14371.1631\n",
      "Epoch 373/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 267584064.0000 - mae: 13325.1201 - val_loss: 264257344.0000 - val_mae: 14363.3701\n",
      "Epoch 374/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 267410176.0000 - mae: 13318.5303 - val_loss: 264031824.0000 - val_mae: 14355.4834\n",
      "Epoch 375/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 267234320.0000 - mae: 13311.8662 - val_loss: 263803760.0000 - val_mae: 14347.5029\n",
      "Epoch 376/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 267056448.0000 - mae: 13305.1201 - val_loss: 263573104.0000 - val_mae: 14339.4258\n",
      "Epoch 377/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 266876512.0000 - mae: 13298.2930 - val_loss: 263339888.0000 - val_mae: 14331.2520\n",
      "Epoch 378/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 266694576.0000 - mae: 13291.3838 - val_loss: 263104032.0000 - val_mae: 14322.9785\n",
      "Epoch 379/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 266510624.0000 - mae: 13284.3926 - val_loss: 262865568.0000 - val_mae: 14314.6094\n",
      "Epoch 380/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 266324624.0000 - mae: 13277.3174 - val_loss: 262624448.0000 - val_mae: 14306.1387\n",
      "Epoch 381/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 266136592.0000 - mae: 13270.1602 - val_loss: 262380672.0000 - val_mae: 14297.5732\n",
      "Epoch 382/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 265946448.0000 - mae: 13262.9180 - val_loss: 262134240.0000 - val_mae: 14288.9014\n",
      "Epoch 383/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 265754256.0000 - mae: 13255.5918 - val_loss: 261885072.0000 - val_mae: 14280.1270\n",
      "Epoch 384/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 265559936.0000 - mae: 13248.1787 - val_loss: 261633200.0000 - val_mae: 14271.2520\n",
      "Epoch 385/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 265363504.0000 - mae: 13240.6797 - val_loss: 261378544.0000 - val_mae: 14262.2715\n",
      "Epoch 386/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 265164944.0000 - mae: 13233.0918 - val_loss: 261121168.0000 - val_mae: 14253.1855\n",
      "Epoch 387/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 264964192.0000 - mae: 13225.4180 - val_loss: 260860928.0000 - val_mae: 14243.9951\n",
      "Epoch 388/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 264761296.0000 - mae: 13217.6523 - val_loss: 260597936.0000 - val_mae: 14234.6963\n",
      "Epoch 389/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 264556256.0000 - mae: 13209.7988 - val_loss: 260332096.0000 - val_mae: 14225.2900\n",
      "Epoch 390/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 264348960.0000 - mae: 13201.8545 - val_loss: 260063408.0000 - val_mae: 14215.7744\n",
      "Epoch 391/1100\n",
      "102/102 [==============================] - 0s 98us/step - loss: 264139456.0000 - mae: 13193.8174 - val_loss: 259791872.0000 - val_mae: 14206.1494\n",
      "Epoch 392/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 263927728.0000 - mae: 13185.6885 - val_loss: 259517440.0000 - val_mae: 14196.4111\n",
      "Epoch 393/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 263713744.0000 - mae: 13177.4668 - val_loss: 259240080.0000 - val_mae: 14186.5625\n",
      "Epoch 394/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 263497552.0000 - mae: 13169.1494 - val_loss: 258959808.0000 - val_mae: 14176.6025\n",
      "Epoch 395/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 263279040.0000 - mae: 13160.7402 - val_loss: 258676592.0000 - val_mae: 14166.5244\n",
      "Epoch 396/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 263058208.0000 - mae: 13152.2314 - val_loss: 258390368.0000 - val_mae: 14156.3340\n",
      "Epoch 397/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 262835024.0000 - mae: 13143.6260 - val_loss: 258101056.0000 - val_mae: 14146.0244\n",
      "Epoch 398/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 262609504.0000 - mae: 13134.9219 - val_loss: 257808816.0000 - val_mae: 14135.5957\n",
      "Epoch 399/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 262381616.0000 - mae: 13126.1172 - val_loss: 257513520.0000 - val_mae: 14125.0518\n",
      "Epoch 400/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 262151376.0000 - mae: 13117.2158 - val_loss: 257215184.0000 - val_mae: 14114.3867\n",
      "Epoch 401/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 261918784.0000 - mae: 13108.2148 - val_loss: 256913760.0000 - val_mae: 14103.6025\n",
      "Epoch 402/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 261683760.0000 - mae: 13099.1113 - val_loss: 256609232.0000 - val_mae: 14092.6963\n",
      "Epoch 403/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 261446352.0000 - mae: 13089.9072 - val_loss: 256301600.0000 - val_mae: 14081.6680\n",
      "Epoch 404/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 261206512.0000 - mae: 13080.5977 - val_loss: 255990864.0000 - val_mae: 14070.5166\n",
      "Epoch 405/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 260964208.0000 - mae: 13071.1865 - val_loss: 255676944.0000 - val_mae: 14059.2383\n",
      "Epoch 406/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 260719472.0000 - mae: 13061.6689 - val_loss: 255359872.0000 - val_mae: 14047.8350\n",
      "Epoch 407/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 260472272.0000 - mae: 13052.0449 - val_loss: 255039584.0000 - val_mae: 14036.3066\n",
      "Epoch 408/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 260222576.0000 - mae: 13042.3184 - val_loss: 254716080.0000 - val_mae: 14024.6465\n",
      "Epoch 409/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 259970384.0000 - mae: 13032.4805 - val_loss: 254389344.0000 - val_mae: 14012.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 259715680.0000 - mae: 13022.5371 - val_loss: 254059376.0000 - val_mae: 14000.9395\n",
      "Epoch 411/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 259458416.0000 - mae: 13012.4824 - val_loss: 253726096.0000 - val_mae: 13988.8887\n",
      "Epoch 412/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 259198576.0000 - mae: 13002.3184 - val_loss: 253389552.0000 - val_mae: 13976.7070\n",
      "Epoch 413/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 258936224.0000 - mae: 12992.0439 - val_loss: 253049632.0000 - val_mae: 13964.3906\n",
      "Epoch 414/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 258671248.0000 - mae: 12981.6572 - val_loss: 252706416.0000 - val_mae: 13951.9375\n",
      "Epoch 415/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 258403712.0000 - mae: 12971.1572 - val_loss: 252359856.0000 - val_mae: 13939.3486\n",
      "Epoch 416/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 258133552.0000 - mae: 12960.5430 - val_loss: 252009904.0000 - val_mae: 13926.6230\n",
      "Epoch 417/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 257860736.0000 - mae: 12949.8135 - val_loss: 251656544.0000 - val_mae: 13913.7588\n",
      "Epoch 418/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 257585296.0000 - mae: 12938.9697 - val_loss: 251299760.0000 - val_mae: 13900.7549\n",
      "Epoch 419/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 257307152.0000 - mae: 12928.0049 - val_loss: 250939536.0000 - val_mae: 13887.6113\n",
      "Epoch 420/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 257026352.0000 - mae: 12916.9238 - val_loss: 250575904.0000 - val_mae: 13874.3213\n",
      "Epoch 421/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 256742848.0000 - mae: 12905.7227 - val_loss: 250208784.0000 - val_mae: 13860.8906\n",
      "Epoch 422/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 256456640.0000 - mae: 12894.4033 - val_loss: 249838160.0000 - val_mae: 13847.3125\n",
      "Epoch 423/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 256167712.0000 - mae: 12882.9600 - val_loss: 249464032.0000 - val_mae: 13833.5898\n",
      "Epoch 424/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 255876048.0000 - mae: 12871.3975 - val_loss: 249086384.0000 - val_mae: 13819.7197\n",
      "Epoch 425/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 255581680.0000 - mae: 12859.7070 - val_loss: 248705168.0000 - val_mae: 13805.7012\n",
      "Epoch 426/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 255284512.0000 - mae: 12847.8945 - val_loss: 248320448.0000 - val_mae: 13791.5322\n",
      "Epoch 427/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 254984576.0000 - mae: 12835.9570 - val_loss: 247932096.0000 - val_mae: 13777.2119\n",
      "Epoch 428/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 254681824.0000 - mae: 12823.8906 - val_loss: 247540160.0000 - val_mae: 13762.7383\n",
      "Epoch 429/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 254376304.0000 - mae: 12811.6973 - val_loss: 247144624.0000 - val_mae: 13748.1133\n",
      "Epoch 430/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 254067936.0000 - mae: 12799.3760 - val_loss: 246745440.0000 - val_mae: 13733.3291\n",
      "Epoch 431/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 253756736.0000 - mae: 12786.9229 - val_loss: 246342624.0000 - val_mae: 13718.3936\n",
      "Epoch 432/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 253442704.0000 - mae: 12774.3398 - val_loss: 245936096.0000 - val_mae: 13703.2969\n",
      "Epoch 433/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 253125808.0000 - mae: 12761.6250 - val_loss: 245525904.0000 - val_mae: 13688.0381\n",
      "Epoch 434/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 252806048.0000 - mae: 12748.7773 - val_loss: 245111952.0000 - val_mae: 13672.6230\n",
      "Epoch 435/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 252483376.0000 - mae: 12735.7939 - val_loss: 244694368.0000 - val_mae: 13657.0430\n",
      "Epoch 436/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 252157824.0000 - mae: 12722.6748 - val_loss: 244273008.0000 - val_mae: 13641.3037\n",
      "Epoch 437/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 251829344.0000 - mae: 12709.4199 - val_loss: 243847872.0000 - val_mae: 13625.3965\n",
      "Epoch 438/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 251497968.0000 - mae: 12696.0283 - val_loss: 243418992.0000 - val_mae: 13609.3242\n",
      "Epoch 439/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 251163648.0000 - mae: 12682.4961 - val_loss: 242986336.0000 - val_mae: 13593.0850\n",
      "Epoch 440/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 250826336.0000 - mae: 12668.8271 - val_loss: 242549856.0000 - val_mae: 13576.6787\n",
      "Epoch 441/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 250486096.0000 - mae: 12655.0146 - val_loss: 242109616.0000 - val_mae: 13560.0986\n",
      "Epoch 442/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 250142864.0000 - mae: 12641.0586 - val_loss: 241665520.0000 - val_mae: 13543.3535\n",
      "Epoch 443/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 249796672.0000 - mae: 12626.9609 - val_loss: 241217616.0000 - val_mae: 13526.4346\n",
      "Epoch 444/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 249447472.0000 - mae: 12612.7197 - val_loss: 240765856.0000 - val_mae: 13509.3389\n",
      "Epoch 445/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 249095232.0000 - mae: 12598.3301 - val_loss: 240310224.0000 - val_mae: 13492.0703\n",
      "Epoch 446/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 248740016.0000 - mae: 12583.7949 - val_loss: 239850720.0000 - val_mae: 13474.6230\n",
      "Epoch 447/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 248381728.0000 - mae: 12569.1123 - val_loss: 239387296.0000 - val_mae: 13456.9980\n",
      "Epoch 448/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 248020384.0000 - mae: 12554.2822 - val_loss: 238919952.0000 - val_mae: 13439.1924\n",
      "Epoch 449/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 247656032.0000 - mae: 12539.2988 - val_loss: 238448672.0000 - val_mae: 13421.2061\n",
      "Epoch 450/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 247288592.0000 - mae: 12524.1641 - val_loss: 237973456.0000 - val_mae: 13403.0381\n",
      "Epoch 451/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 246918096.0000 - mae: 12508.8789 - val_loss: 237494304.0000 - val_mae: 13384.6826\n",
      "Epoch 452/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 246544480.0000 - mae: 12493.4375 - val_loss: 237011216.0000 - val_mae: 13366.1445\n",
      "Epoch 453/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 246167760.0000 - mae: 12477.8398 - val_loss: 236524144.0000 - val_mae: 13347.4189\n",
      "Epoch 454/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 245787984.0000 - mae: 12462.0869 - val_loss: 236033104.0000 - val_mae: 13328.5078\n",
      "Epoch 455/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 245405072.0000 - mae: 12446.1768 - val_loss: 235538064.0000 - val_mae: 13309.4023\n",
      "Epoch 456/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 245019072.0000 - mae: 12430.1074 - val_loss: 235039024.0000 - val_mae: 13290.1084\n",
      "Epoch 457/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 244629888.0000 - mae: 12413.8799 - val_loss: 234535984.0000 - val_mae: 13270.6201\n",
      "Epoch 458/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 244237616.0000 - mae: 12397.4893 - val_loss: 234028928.0000 - val_mae: 13250.9404\n",
      "Epoch 459/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 243842192.0000 - mae: 12380.9375 - val_loss: 233517888.0000 - val_mae: 13231.0645\n",
      "Epoch 460/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 243443584.0000 - mae: 12364.2207 - val_loss: 233002752.0000 - val_mae: 13210.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 243041856.0000 - mae: 12347.3398 - val_loss: 232483584.0000 - val_mae: 13190.7168\n",
      "Epoch 462/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 242636960.0000 - mae: 12330.2920 - val_loss: 231960432.0000 - val_mae: 13170.2422\n",
      "Epoch 463/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 242228864.0000 - mae: 12313.0771 - val_loss: 231433136.0000 - val_mae: 13149.5674\n",
      "Epoch 464/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 241817552.0000 - mae: 12295.6914 - val_loss: 230901792.0000 - val_mae: 13128.6875\n",
      "Epoch 465/1100\n",
      "102/102 [==============================] - 0s 186us/step - loss: 241403088.0000 - mae: 12278.1387 - val_loss: 230366384.0000 - val_mae: 13107.6035\n",
      "Epoch 466/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 240985408.0000 - mae: 12260.4102 - val_loss: 229826880.0000 - val_mae: 13086.3125\n",
      "Epoch 467/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 240564528.0000 - mae: 12242.5098 - val_loss: 229283360.0000 - val_mae: 13064.8145\n",
      "Epoch 468/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 240140464.0000 - mae: 12224.4404 - val_loss: 228735728.0000 - val_mae: 13043.1084\n",
      "Epoch 469/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 239713200.0000 - mae: 12206.1914 - val_loss: 228184032.0000 - val_mae: 13021.1904\n",
      "Epoch 470/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 239282752.0000 - mae: 12187.7686 - val_loss: 227628224.0000 - val_mae: 12999.0596\n",
      "Epoch 471/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 238849072.0000 - mae: 12169.1670 - val_loss: 227068336.0000 - val_mae: 12976.7139\n",
      "Epoch 472/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 238412176.0000 - mae: 12150.3857 - val_loss: 226504352.0000 - val_mae: 12954.1543\n",
      "Epoch 473/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 237972096.0000 - mae: 12131.4248 - val_loss: 225936288.0000 - val_mae: 12931.3770\n",
      "Epoch 474/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 237528784.0000 - mae: 12112.2822 - val_loss: 225364112.0000 - val_mae: 12908.3799\n",
      "Epoch 475/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 237082224.0000 - mae: 12092.9561 - val_loss: 224787824.0000 - val_mae: 12885.1650\n",
      "Epoch 476/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 236632464.0000 - mae: 12073.4453 - val_loss: 224207472.0000 - val_mae: 12861.7256\n",
      "Epoch 477/1100\n",
      "102/102 [==============================] - 0s 59us/step - loss: 236179504.0000 - mae: 12053.7500 - val_loss: 223623040.0000 - val_mae: 12838.0625\n",
      "Epoch 478/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 235723280.0000 - mae: 12033.8652 - val_loss: 223034496.0000 - val_mae: 12814.1758\n",
      "Epoch 479/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 235263792.0000 - mae: 12013.7930 - val_loss: 222441872.0000 - val_mae: 12790.0625\n",
      "Epoch 480/1100\n",
      "102/102 [==============================] - 0s 206us/step - loss: 234801136.0000 - mae: 11993.5293 - val_loss: 221845152.0000 - val_mae: 12765.7197\n",
      "Epoch 481/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 234335232.0000 - mae: 11973.0762 - val_loss: 221244384.0000 - val_mae: 12741.1465\n",
      "Epoch 482/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 233866096.0000 - mae: 11952.4287 - val_loss: 220639504.0000 - val_mae: 12716.3428\n",
      "Epoch 483/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 233393792.0000 - mae: 11931.5908 - val_loss: 220030544.0000 - val_mae: 12691.3057\n",
      "Epoch 484/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 232918256.0000 - mae: 11910.5576 - val_loss: 219417520.0000 - val_mae: 12666.0352\n",
      "Epoch 485/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 232439504.0000 - mae: 11889.3252 - val_loss: 218800448.0000 - val_mae: 12640.5254\n",
      "Epoch 486/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 231957568.0000 - mae: 11868.3027 - val_loss: 218179328.0000 - val_mae: 12614.7793\n",
      "Epoch 487/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 231472432.0000 - mae: 11848.3125 - val_loss: 217554112.0000 - val_mae: 12588.7930\n",
      "Epoch 488/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 230984064.0000 - mae: 11828.1348 - val_loss: 216924928.0000 - val_mae: 12562.5645\n",
      "Epoch 489/1100\n",
      "102/102 [==============================] - 0s 118us/step - loss: 230492528.0000 - mae: 11807.7725 - val_loss: 216291680.0000 - val_mae: 12536.0928\n",
      "Epoch 490/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 229997824.0000 - mae: 11787.2197 - val_loss: 215654432.0000 - val_mae: 12509.3789\n",
      "Epoch 491/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 229499952.0000 - mae: 11766.4795 - val_loss: 215013120.0000 - val_mae: 12482.4150\n",
      "Epoch 492/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 228998848.0000 - mae: 11745.5488 - val_loss: 214367888.0000 - val_mae: 12455.2061\n",
      "Epoch 493/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 228494640.0000 - mae: 11724.4277 - val_loss: 213718640.0000 - val_mae: 12427.7451\n",
      "Epoch 494/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 227987280.0000 - mae: 11703.1123 - val_loss: 213065424.0000 - val_mae: 12400.0332\n",
      "Epoch 495/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 227476768.0000 - mae: 11681.6025 - val_loss: 212408272.0000 - val_mae: 12372.0703\n",
      "Epoch 496/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 226963088.0000 - mae: 11659.8975 - val_loss: 211747168.0000 - val_mae: 12343.8496\n",
      "Epoch 497/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 226446288.0000 - mae: 11637.9951 - val_loss: 211082144.0000 - val_mae: 12315.3760\n",
      "Epoch 498/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 225926224.0000 - mae: 11615.8848 - val_loss: 210413216.0000 - val_mae: 12286.6445\n",
      "Epoch 499/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 225403024.0000 - mae: 11593.5752 - val_loss: 209740400.0000 - val_mae: 12257.6514\n",
      "Epoch 500/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 224876752.0000 - mae: 11571.0654 - val_loss: 209063728.0000 - val_mae: 12228.3975\n",
      "Epoch 501/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 224347424.0000 - mae: 11548.3545 - val_loss: 208383216.0000 - val_mae: 12198.8789\n",
      "Epoch 502/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 223815040.0000 - mae: 11525.4385 - val_loss: 207698864.0000 - val_mae: 12169.0967\n",
      "Epoch 503/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 223279648.0000 - mae: 11502.3213 - val_loss: 207010736.0000 - val_mae: 12139.0498\n",
      "Epoch 504/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 222741184.0000 - mae: 11478.9961 - val_loss: 206318832.0000 - val_mae: 12108.7305\n",
      "Epoch 505/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 222199728.0000 - mae: 11455.4648 - val_loss: 205623168.0000 - val_mae: 12078.1445\n",
      "Epoch 506/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 221655280.0000 - mae: 11431.7246 - val_loss: 204923776.0000 - val_mae: 12047.2861\n",
      "Epoch 507/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 221107856.0000 - mae: 11407.7744 - val_loss: 204220704.0000 - val_mae: 12016.1553\n",
      "Epoch 508/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 220557520.0000 - mae: 11383.6152 - val_loss: 203513936.0000 - val_mae: 11984.7490\n",
      "Epoch 509/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 220004176.0000 - mae: 11359.2422 - val_loss: 202803568.0000 - val_mae: 11953.0664\n",
      "Epoch 510/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 219447936.0000 - mae: 11334.6572 - val_loss: 202089568.0000 - val_mae: 11921.1064\n",
      "Epoch 511/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 218888832.0000 - mae: 11310.8945 - val_loss: 201372000.0000 - val_mae: 11892.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 218326832.0000 - mae: 11287.5654 - val_loss: 200650896.0000 - val_mae: 11864.3242\n",
      "Epoch 513/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 217762000.0000 - mae: 11264.0293 - val_loss: 199926240.0000 - val_mae: 11835.7861\n",
      "Epoch 514/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 217194288.0000 - mae: 11240.2900 - val_loss: 199198144.0000 - val_mae: 11806.9980\n",
      "Epoch 515/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 216623872.0000 - mae: 11216.3477 - val_loss: 198466608.0000 - val_mae: 11777.9629\n",
      "Epoch 516/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 216050560.0000 - mae: 11192.1963 - val_loss: 197731680.0000 - val_mae: 11748.6758\n",
      "Epoch 517/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 215474576.0000 - mae: 11167.8398 - val_loss: 196993392.0000 - val_mae: 11719.1348\n",
      "Epoch 518/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 214895872.0000 - mae: 11143.2734 - val_loss: 196251744.0000 - val_mae: 11689.3418\n",
      "Epoch 519/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 214314464.0000 - mae: 11119.0078 - val_loss: 195506848.0000 - val_mae: 11659.2920\n",
      "Epoch 520/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 213730368.0000 - mae: 11095.4414 - val_loss: 194758736.0000 - val_mae: 11628.9873\n",
      "Epoch 521/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 213143648.0000 - mae: 11071.6768 - val_loss: 194007392.0000 - val_mae: 11598.4229\n",
      "Epoch 522/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 212554336.0000 - mae: 11047.7100 - val_loss: 193252912.0000 - val_mae: 11567.5986\n",
      "Epoch 523/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 211962480.0000 - mae: 11023.5381 - val_loss: 192495328.0000 - val_mae: 11536.5146\n",
      "Epoch 524/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 211368064.0000 - mae: 10999.1670 - val_loss: 191734720.0000 - val_mae: 11505.1680\n",
      "Epoch 525/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 210771152.0000 - mae: 10974.5869 - val_loss: 190971104.0000 - val_mae: 11473.5576\n",
      "Epoch 526/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 210171776.0000 - mae: 10949.7998 - val_loss: 190204544.0000 - val_mae: 11441.6816\n",
      "Epoch 527/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 209569968.0000 - mae: 10924.8076 - val_loss: 189435072.0000 - val_mae: 11409.5391\n",
      "Epoch 528/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 208965776.0000 - mae: 10899.6064 - val_loss: 188662784.0000 - val_mae: 11377.1270\n",
      "Epoch 529/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 208359248.0000 - mae: 10875.0977 - val_loss: 187887696.0000 - val_mae: 11344.4473\n",
      "Epoch 530/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 207750368.0000 - mae: 10850.9375 - val_loss: 187109904.0000 - val_mae: 11311.4980\n",
      "Epoch 531/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 207139232.0000 - mae: 10826.5762 - val_loss: 186329408.0000 - val_mae: 11278.2754\n",
      "Epoch 532/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 206525904.0000 - mae: 10802.0176 - val_loss: 185546336.0000 - val_mae: 11244.7793\n",
      "Epoch 533/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 205910352.0000 - mae: 10777.2549 - val_loss: 184760720.0000 - val_mae: 11211.0088\n",
      "Epoch 534/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 205292704.0000 - mae: 10752.3750 - val_loss: 183972608.0000 - val_mae: 11176.9629\n",
      "Epoch 535/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 204672944.0000 - mae: 10728.5254 - val_loss: 183182096.0000 - val_mae: 11142.6377\n",
      "Epoch 536/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 204051152.0000 - mae: 10704.4814 - val_loss: 182389232.0000 - val_mae: 11108.0352\n",
      "Epoch 537/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 203427344.0000 - mae: 10680.2451 - val_loss: 181594096.0000 - val_mae: 11073.1533\n",
      "Epoch 538/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 202801616.0000 - mae: 10655.8096 - val_loss: 180796752.0000 - val_mae: 11037.9902\n",
      "Epoch 539/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 202173968.0000 - mae: 10631.1797 - val_loss: 179997248.0000 - val_mae: 11002.5439\n",
      "Epoch 540/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 201544464.0000 - mae: 10606.3525 - val_loss: 179195712.0000 - val_mae: 10966.8154\n",
      "Epoch 541/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 200913184.0000 - mae: 10581.3262 - val_loss: 178392192.0000 - val_mae: 10930.8018\n",
      "Epoch 542/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 200280128.0000 - mae: 10557.1914 - val_loss: 177586752.0000 - val_mae: 10894.5029\n",
      "Epoch 543/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 199645424.0000 - mae: 10533.0029 - val_loss: 176779360.0000 - val_mae: 10857.9111\n",
      "Epoch 544/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 199008976.0000 - mae: 10508.6172 - val_loss: 175970240.0000 - val_mae: 10821.0332\n",
      "Epoch 545/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 198370928.0000 - mae: 10484.0420 - val_loss: 175159472.0000 - val_mae: 10783.8662\n",
      "Epoch 546/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 197731392.0000 - mae: 10459.2705 - val_loss: 174347136.0000 - val_mae: 10746.4102\n",
      "Epoch 547/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 197090432.0000 - mae: 10434.3076 - val_loss: 173533280.0000 - val_mae: 10708.6631\n",
      "Epoch 548/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 196448048.0000 - mae: 10410.0225 - val_loss: 172718048.0000 - val_mae: 10671.7168\n",
      "Epoch 549/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 195804368.0000 - mae: 10386.3027 - val_loss: 171901520.0000 - val_mae: 10636.4414\n",
      "Epoch 550/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 195159408.0000 - mae: 10362.3975 - val_loss: 171083744.0000 - val_mae: 10600.8975\n",
      "Epoch 551/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 194513264.0000 - mae: 10338.3066 - val_loss: 170264832.0000 - val_mae: 10565.0820\n",
      "Epoch 552/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 193865952.0000 - mae: 10314.0283 - val_loss: 169444896.0000 - val_mae: 10528.9941\n",
      "Epoch 553/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 193217632.0000 - mae: 10289.5635 - val_loss: 168623968.0000 - val_mae: 10492.6328\n",
      "Epoch 554/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 192568272.0000 - mae: 10266.5098 - val_loss: 167802224.0000 - val_mae: 10456.0000\n",
      "Epoch 555/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 191917984.0000 - mae: 10244.1006 - val_loss: 166979728.0000 - val_mae: 10419.0938\n",
      "Epoch 556/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 191266768.0000 - mae: 10221.5156 - val_loss: 166156544.0000 - val_mae: 10381.9150\n",
      "Epoch 557/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 190614704.0000 - mae: 10198.7529 - val_loss: 165332848.0000 - val_mae: 10346.1152\n",
      "Epoch 558/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 189961872.0000 - mae: 10175.8154 - val_loss: 164508752.0000 - val_mae: 10311.0986\n",
      "Epoch 559/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 189308400.0000 - mae: 10152.7002 - val_loss: 163684304.0000 - val_mae: 10275.8271\n",
      "Epoch 560/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 188654272.0000 - mae: 10129.4053 - val_loss: 162859664.0000 - val_mae: 10244.2490\n",
      "Epoch 561/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 187999632.0000 - mae: 10105.9316 - val_loss: 162035008.0000 - val_mae: 10213.9971\n",
      "Epoch 562/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 187344528.0000 - mae: 10082.2803 - val_loss: 161210416.0000 - val_mae: 10183.5195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563/1100\n",
      "102/102 [==============================] - 0s 235us/step - loss: 186689040.0000 - mae: 10058.4453 - val_loss: 160386032.0000 - val_mae: 10155.4492\n",
      "Epoch 564/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 186033248.0000 - mae: 10034.4307 - val_loss: 159561984.0000 - val_mae: 10128.0059\n",
      "Epoch 565/1100\n",
      "102/102 [==============================] - 0s 69us/step - loss: 185377184.0000 - mae: 10010.2314 - val_loss: 158738384.0000 - val_mae: 10100.3574\n",
      "Epoch 566/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 184720960.0000 - mae: 9985.8496 - val_loss: 157915392.0000 - val_mae: 10072.5010\n",
      "Epoch 567/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 184064624.0000 - mae: 9961.2998 - val_loss: 157093024.0000 - val_mae: 10044.4336\n",
      "Epoch 568/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 183408240.0000 - mae: 9938.3711 - val_loss: 156271488.0000 - val_mae: 10016.1582\n",
      "Epoch 569/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 182751920.0000 - mae: 9915.4580 - val_loss: 155450896.0000 - val_mae: 9987.6748\n",
      "Epoch 570/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 182095712.0000 - mae: 9892.3682 - val_loss: 154631344.0000 - val_mae: 9958.9805\n",
      "Epoch 571/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 181439664.0000 - mae: 9869.1045 - val_loss: 153813008.0000 - val_mae: 9930.0781\n",
      "Epoch 572/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 180783920.0000 - mae: 9845.6650 - val_loss: 152995984.0000 - val_mae: 9900.9639\n",
      "Epoch 573/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 180128512.0000 - mae: 9822.0498 - val_loss: 152180432.0000 - val_mae: 9871.6416\n",
      "Epoch 574/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 179473536.0000 - mae: 9798.2559 - val_loss: 151366496.0000 - val_mae: 9842.1055\n",
      "Epoch 575/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 178819024.0000 - mae: 9774.2852 - val_loss: 150554304.0000 - val_mae: 9812.3594\n",
      "Epoch 576/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 178165136.0000 - mae: 9750.1357 - val_loss: 149744000.0000 - val_mae: 9782.4004\n",
      "Epoch 577/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 177511888.0000 - mae: 9725.8057 - val_loss: 148935696.0000 - val_mae: 9752.2285\n",
      "Epoch 578/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 176859360.0000 - mae: 9701.2949 - val_loss: 148129536.0000 - val_mae: 9721.8418\n",
      "Epoch 579/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 176207616.0000 - mae: 9676.6025 - val_loss: 147325600.0000 - val_mae: 9691.2441\n",
      "Epoch 580/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 175556704.0000 - mae: 9651.7295 - val_loss: 146524064.0000 - val_mae: 9660.4297\n",
      "Epoch 581/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 174906768.0000 - mae: 9626.6748 - val_loss: 145724960.0000 - val_mae: 9629.4014\n",
      "Epoch 582/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 174257856.0000 - mae: 9601.6553 - val_loss: 144928448.0000 - val_mae: 9598.1562\n",
      "Epoch 583/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 173610048.0000 - mae: 9577.7578 - val_loss: 144134656.0000 - val_mae: 9566.6973\n",
      "Epoch 584/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 172963392.0000 - mae: 9553.6914 - val_loss: 143343680.0000 - val_mae: 9535.0234\n",
      "Epoch 585/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 172318032.0000 - mae: 9529.4531 - val_loss: 142555664.0000 - val_mae: 9504.4463\n",
      "Epoch 586/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 171674000.0000 - mae: 9505.0420 - val_loss: 141770752.0000 - val_mae: 9475.8105\n",
      "Epoch 587/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 171031392.0000 - mae: 9480.4580 - val_loss: 140989056.0000 - val_mae: 9446.9834\n",
      "Epoch 588/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 170390304.0000 - mae: 9455.7031 - val_loss: 140210768.0000 - val_mae: 9417.9678\n",
      "Epoch 589/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 169750864.0000 - mae: 9431.0566 - val_loss: 139435968.0000 - val_mae: 9391.8584\n",
      "Epoch 590/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 169113120.0000 - mae: 9407.1650 - val_loss: 138664832.0000 - val_mae: 9368.5547\n",
      "Epoch 591/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 168477168.0000 - mae: 9383.1250 - val_loss: 137897504.0000 - val_mae: 9345.1055\n",
      "Epoch 592/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 167843120.0000 - mae: 9360.5127 - val_loss: 137134112.0000 - val_mae: 9323.4805\n",
      "Epoch 593/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 167211072.0000 - mae: 9337.7461 - val_loss: 136374752.0000 - val_mae: 9302.5791\n",
      "Epoch 594/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 166581008.0000 - mae: 9314.8232 - val_loss: 135619664.0000 - val_mae: 9281.5430\n",
      "Epoch 595/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 165952992.0000 - mae: 9292.0850 - val_loss: 134868864.0000 - val_mae: 9260.3672\n",
      "Epoch 596/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 165327184.0000 - mae: 9269.7920 - val_loss: 134122536.0000 - val_mae: 9239.0557\n",
      "Epoch 597/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 164703696.0000 - mae: 9247.3516 - val_loss: 133380784.0000 - val_mae: 9217.6064\n",
      "Epoch 598/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 164082576.0000 - mae: 9224.7637 - val_loss: 132643776.0000 - val_mae: 9196.0176\n",
      "Epoch 599/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 163463920.0000 - mae: 9202.0254 - val_loss: 131911640.0000 - val_mae: 9174.2900\n",
      "Epoch 600/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 162847760.0000 - mae: 9179.1406 - val_loss: 131184504.0000 - val_mae: 9152.4258\n",
      "Epoch 601/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 162234192.0000 - mae: 9156.5596 - val_loss: 130462480.0000 - val_mae: 9130.4229\n",
      "Epoch 602/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 161623248.0000 - mae: 9134.4727 - val_loss: 129745704.0000 - val_mae: 9108.2793\n",
      "Epoch 603/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 161014992.0000 - mae: 9112.9102 - val_loss: 129034216.0000 - val_mae: 9085.9980\n",
      "Epoch 604/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 160409440.0000 - mae: 9091.7051 - val_loss: 128328128.0000 - val_mae: 9063.5781\n",
      "Epoch 605/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 159806768.0000 - mae: 9070.3672 - val_loss: 127627592.0000 - val_mae: 9041.0225\n",
      "Epoch 606/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 159206992.0000 - mae: 9048.8975 - val_loss: 126932640.0000 - val_mae: 9018.3291\n",
      "Epoch 607/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 158610224.0000 - mae: 9027.2969 - val_loss: 126243416.0000 - val_mae: 8995.4990\n",
      "Epoch 608/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 158016496.0000 - mae: 9005.5664 - val_loss: 125559984.0000 - val_mae: 8972.5361\n",
      "Epoch 609/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 157425936.0000 - mae: 8984.9766 - val_loss: 124882392.0000 - val_mae: 8949.4355\n",
      "Epoch 610/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 156838592.0000 - mae: 8965.3574 - val_loss: 124210728.0000 - val_mae: 8926.2002\n",
      "Epoch 611/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 156254544.0000 - mae: 8945.6201 - val_loss: 123545072.0000 - val_mae: 8902.8330\n",
      "Epoch 612/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 155673936.0000 - mae: 8925.7637 - val_loss: 122885496.0000 - val_mae: 8879.3291\n",
      "Epoch 613/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 155096800.0000 - mae: 8905.7891 - val_loss: 122232080.0000 - val_mae: 8855.6924\n",
      "Epoch 614/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 154523296.0000 - mae: 8886.6885 - val_loss: 121584616.0000 - val_mae: 8831.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 153953408.0000 - mae: 8868.2646 - val_loss: 120942680.0000 - val_mae: 8807.9678\n",
      "Epoch 616/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 153387328.0000 - mae: 8849.8340 - val_loss: 120307152.0000 - val_mae: 8783.8916\n",
      "Epoch 617/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 152825136.0000 - mae: 8831.2959 - val_loss: 119678040.0000 - val_mae: 8759.6729\n",
      "Epoch 618/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 152267008.0000 - mae: 8812.6562 - val_loss: 119055712.0000 - val_mae: 8735.3252\n",
      "Epoch 619/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 151712992.0000 - mae: 8794.1670 - val_loss: 118440408.0000 - val_mae: 8710.8564\n",
      "Epoch 620/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 151163152.0000 - mae: 8778.0898 - val_loss: 117832264.0000 - val_mae: 8686.2656\n",
      "Epoch 621/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 150617664.0000 - mae: 8761.9346 - val_loss: 117231440.0000 - val_mae: 8661.5537\n",
      "Epoch 622/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 150076656.0000 - mae: 8745.6914 - val_loss: 116638048.0000 - val_mae: 8636.7227\n",
      "Epoch 623/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 149540176.0000 - mae: 8729.3574 - val_loss: 116052280.0000 - val_mae: 8611.7754\n",
      "Epoch 624/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 149008256.0000 - mae: 8712.9365 - val_loss: 115474280.0000 - val_mae: 8586.7139\n",
      "Epoch 625/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 148481008.0000 - mae: 8696.4248 - val_loss: 114904192.0000 - val_mae: 8561.5400\n",
      "Epoch 626/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 147958496.0000 - mae: 8679.8213 - val_loss: 114342112.0000 - val_mae: 8536.2529\n",
      "Epoch 627/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 147440672.0000 - mae: 8663.1309 - val_loss: 113788192.0000 - val_mae: 8510.8535\n",
      "Epoch 628/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 146927648.0000 - mae: 8646.3535 - val_loss: 113242528.0000 - val_mae: 8485.3516\n",
      "Epoch 629/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 146419392.0000 - mae: 8630.1719 - val_loss: 112705208.0000 - val_mae: 8459.7451\n",
      "Epoch 630/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 145915888.0000 - mae: 8614.9971 - val_loss: 112176312.0000 - val_mae: 8434.0400\n",
      "Epoch 631/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 145417104.0000 - mae: 8600.5088 - val_loss: 111655840.0000 - val_mae: 8408.2383\n",
      "Epoch 632/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 144922928.0000 - mae: 8586.4385 - val_loss: 111143960.0000 - val_mae: 8382.3477\n",
      "Epoch 633/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 144433568.0000 - mae: 8572.3018 - val_loss: 110640704.0000 - val_mae: 8356.3721\n",
      "Epoch 634/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 143949008.0000 - mae: 8558.1016 - val_loss: 110146032.0000 - val_mae: 8330.3174\n",
      "Epoch 635/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 143469200.0000 - mae: 8544.0322 - val_loss: 109660032.0000 - val_mae: 8304.1885\n",
      "Epoch 636/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 142994080.0000 - mae: 8532.4873 - val_loss: 109182640.0000 - val_mae: 8277.9893\n",
      "Epoch 637/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 142523600.0000 - mae: 8523.0225 - val_loss: 108713784.0000 - val_mae: 8251.7236\n",
      "Epoch 638/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 142057648.0000 - mae: 8513.6338 - val_loss: 108253472.0000 - val_mae: 8225.3984\n",
      "Epoch 639/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 141596256.0000 - mae: 8504.7900 - val_loss: 107801576.0000 - val_mae: 8199.0156\n",
      "Epoch 640/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 141139328.0000 - mae: 8495.8623 - val_loss: 107358048.0000 - val_mae: 8172.5825\n",
      "Epoch 641/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 140686512.0000 - mae: 8486.8447 - val_loss: 106922792.0000 - val_mae: 8146.0962\n",
      "Epoch 642/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 140237504.0000 - mae: 8477.7188 - val_loss: 106495576.0000 - val_mae: 8119.5586\n",
      "Epoch 643/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 139792880.0000 - mae: 8468.5166 - val_loss: 106076360.0000 - val_mae: 8092.9741\n",
      "Epoch 644/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 139352672.0000 - mae: 8459.2402 - val_loss: 105664512.0000 - val_mae: 8066.3101\n",
      "Epoch 645/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 138916864.0000 - mae: 8449.8896 - val_loss: 105260272.0000 - val_mae: 8039.5869\n",
      "Epoch 646/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 138485312.0000 - mae: 8441.8184 - val_loss: 104863784.0000 - val_mae: 8012.8149\n",
      "Epoch 647/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 138058224.0000 - mae: 8435.0342 - val_loss: 104474976.0000 - val_mae: 7986.1621\n",
      "Epoch 648/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 137635616.0000 - mae: 8428.1914 - val_loss: 104093824.0000 - val_mae: 7961.7783\n",
      "Epoch 649/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 137217552.0000 - mae: 8422.4336 - val_loss: 103720336.0000 - val_mae: 7937.3560\n",
      "Epoch 650/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 136804128.0000 - mae: 8416.9336 - val_loss: 103354448.0000 - val_mae: 7912.8955\n",
      "Epoch 651/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 136395328.0000 - mae: 8411.3887 - val_loss: 102996224.0000 - val_mae: 7891.4019\n",
      "Epoch 652/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 135990992.0000 - mae: 8405.7988 - val_loss: 102645464.0000 - val_mae: 7871.6387\n",
      "Epoch 653/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 135590896.0000 - mae: 8400.1436 - val_loss: 102302240.0000 - val_mae: 7853.6860\n",
      "Epoch 654/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 135195504.0000 - mae: 8394.4453 - val_loss: 101966760.0000 - val_mae: 7835.7266\n",
      "Epoch 655/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 134805184.0000 - mae: 8388.7148 - val_loss: 101639072.0000 - val_mae: 7817.7632\n",
      "Epoch 656/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 134420032.0000 - mae: 8382.9561 - val_loss: 101319248.0000 - val_mae: 7799.7993\n",
      "Epoch 657/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 134040072.0000 - mae: 8377.1670 - val_loss: 101007368.0000 - val_mae: 7781.8394\n",
      "Epoch 658/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 133665440.0000 - mae: 8371.3477 - val_loss: 100703504.0000 - val_mae: 7763.8911\n",
      "Epoch 659/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 133296136.0000 - mae: 8365.5039 - val_loss: 100407720.0000 - val_mae: 7745.9580\n",
      "Epoch 660/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 132932256.0000 - mae: 8359.7705 - val_loss: 100120080.0000 - val_mae: 7728.0493\n",
      "Epoch 661/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 132573880.0000 - mae: 8355.4707 - val_loss: 99840664.0000 - val_mae: 7710.1724\n",
      "Epoch 662/1100\n",
      "102/102 [==============================] - 0s 98us/step - loss: 132220920.0000 - mae: 8351.1436 - val_loss: 99569352.0000 - val_mae: 7695.7935\n",
      "Epoch 663/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 131873128.0000 - mae: 8346.7725 - val_loss: 99306352.0000 - val_mae: 7682.2646\n",
      "Epoch 664/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 131531024.0000 - mae: 8342.3838 - val_loss: 99051712.0000 - val_mae: 7668.7959\n",
      "Epoch 665/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 131194592.0000 - mae: 8337.9775 - val_loss: 98805336.0000 - val_mae: 7655.3843\n",
      "Epoch 666/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 130863848.0000 - mae: 8333.5518 - val_loss: 98567336.0000 - val_mae: 7642.0444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 130538576.0000 - mae: 8329.1016 - val_loss: 98337832.0000 - val_mae: 7628.7690\n",
      "Epoch 668/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 130216952.0000 - mae: 8324.5664 - val_loss: 98116728.0000 - val_mae: 7616.5220\n",
      "Epoch 669/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 129901296.0000 - mae: 8320.0195 - val_loss: 97903928.0000 - val_mae: 7605.2227\n",
      "Epoch 670/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 129591544.0000 - mae: 8315.4600 - val_loss: 97699424.0000 - val_mae: 7594.9175\n",
      "Epoch 671/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 129287712.0000 - mae: 8310.8877 - val_loss: 97503120.0000 - val_mae: 7585.0474\n",
      "Epoch 672/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 128989776.0000 - mae: 8306.2979 - val_loss: 97314928.0000 - val_mae: 7575.2188\n",
      "Epoch 673/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 128697744.0000 - mae: 8301.6924 - val_loss: 97134736.0000 - val_mae: 7565.4307\n",
      "Epoch 674/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 128411576.0000 - mae: 8297.0693 - val_loss: 96962424.0000 - val_mae: 7555.6807\n",
      "Epoch 675/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 128131320.0000 - mae: 8292.4258 - val_loss: 96797880.0000 - val_mae: 7545.9673\n",
      "Epoch 676/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 127856960.0000 - mae: 8287.7617 - val_loss: 96640928.0000 - val_mae: 7536.2759\n",
      "Epoch 677/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 127588432.0000 - mae: 8283.0781 - val_loss: 96491456.0000 - val_mae: 7526.6182\n",
      "Epoch 678/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 127325824.0000 - mae: 8278.9072 - val_loss: 96349320.0000 - val_mae: 7516.9922\n",
      "Epoch 679/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 127069080.0000 - mae: 8275.0332 - val_loss: 96214376.0000 - val_mae: 7507.3965\n",
      "Epoch 680/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 126818200.0000 - mae: 8271.1279 - val_loss: 96086456.0000 - val_mae: 7497.8291\n",
      "Epoch 681/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 126573168.0000 - mae: 8267.1885 - val_loss: 95965416.0000 - val_mae: 7488.2925\n",
      "Epoch 682/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 126333952.0000 - mae: 8263.2178 - val_loss: 95850640.0000 - val_mae: 7478.7568\n",
      "Epoch 683/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 126100488.0000 - mae: 8259.3506 - val_loss: 95742368.0000 - val_mae: 7469.2485\n",
      "Epoch 684/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 125872752.0000 - mae: 8255.5977 - val_loss: 95640464.0000 - val_mae: 7459.7769\n",
      "Epoch 685/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 125650720.0000 - mae: 8251.8037 - val_loss: 95544816.0000 - val_mae: 7450.3447\n",
      "Epoch 686/1100\n",
      "102/102 [==============================] - 0s 216us/step - loss: 125434328.0000 - mae: 8247.9707 - val_loss: 95455216.0000 - val_mae: 7441.6191\n",
      "Epoch 687/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 125223488.0000 - mae: 8244.0986 - val_loss: 95371504.0000 - val_mae: 7437.1577\n",
      "Epoch 688/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 125018160.0000 - mae: 8240.1885 - val_loss: 95293472.0000 - val_mae: 7432.6914\n",
      "Epoch 689/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 124818160.0000 - mae: 8237.0576 - val_loss: 95220816.0000 - val_mae: 7428.2378\n",
      "Epoch 690/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 124623192.0000 - mae: 8234.5752 - val_loss: 95153352.0000 - val_mae: 7423.7715\n",
      "Epoch 691/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 124433528.0000 - mae: 8232.0449 - val_loss: 95090784.0000 - val_mae: 7419.2959\n",
      "Epoch 692/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 124249088.0000 - mae: 8229.7090 - val_loss: 95032832.0000 - val_mae: 7414.8149\n",
      "Epoch 693/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 124069696.0000 - mae: 8227.5039 - val_loss: 94979032.0000 - val_mae: 7410.3208\n",
      "Epoch 694/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 123895224.0000 - mae: 8225.2383 - val_loss: 94929056.0000 - val_mae: 7408.4155\n",
      "Epoch 695/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 123725560.0000 - mae: 8222.9102 - val_loss: 94882632.0000 - val_mae: 7407.0054\n",
      "Epoch 696/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 123560512.0000 - mae: 8220.8779 - val_loss: 94839408.0000 - val_mae: 7405.5303\n",
      "Epoch 697/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 123399920.0000 - mae: 8219.6172 - val_loss: 94799000.0000 - val_mae: 7403.9888\n",
      "Epoch 698/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 123243624.0000 - mae: 8218.2637 - val_loss: 94761056.0000 - val_mae: 7402.3794\n",
      "Epoch 699/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 123091448.0000 - mae: 8216.8252 - val_loss: 94725192.0000 - val_mae: 7400.7041\n",
      "Epoch 700/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 122943168.0000 - mae: 8216.4189 - val_loss: 94690928.0000 - val_mae: 7398.9634\n",
      "Epoch 701/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 122798320.0000 - mae: 8215.8555 - val_loss: 94658040.0000 - val_mae: 7397.1577\n",
      "Epoch 702/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 122657008.0000 - mae: 8215.1631 - val_loss: 94626120.0000 - val_mae: 7395.2866\n",
      "Epoch 703/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 122519040.0000 - mae: 8214.3408 - val_loss: 94594880.0000 - val_mae: 7393.3535\n",
      "Epoch 704/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 122384184.0000 - mae: 8213.3877 - val_loss: 94563984.0000 - val_mae: 7391.3589\n",
      "Epoch 705/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 122252256.0000 - mae: 8212.3008 - val_loss: 94533184.0000 - val_mae: 7389.3110\n",
      "Epoch 706/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 122123040.0000 - mae: 8211.0840 - val_loss: 94502200.0000 - val_mae: 7387.2104\n",
      "Epoch 707/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 121996336.0000 - mae: 8209.7373 - val_loss: 94470872.0000 - val_mae: 7385.0635\n",
      "Epoch 708/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 121871992.0000 - mae: 8208.2656 - val_loss: 94439000.0000 - val_mae: 7382.8735\n",
      "Epoch 709/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 121749824.0000 - mae: 8206.6699 - val_loss: 94405928.0000 - val_mae: 7380.6240\n",
      "Epoch 710/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 121629664.0000 - mae: 8204.9570 - val_loss: 94371560.0000 - val_mae: 7378.3179\n",
      "Epoch 711/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 121511376.0000 - mae: 8203.3232 - val_loss: 94336360.0000 - val_mae: 7376.3618\n",
      "Epoch 712/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 121394840.0000 - mae: 8201.7109 - val_loss: 94300256.0000 - val_mae: 7375.3306\n",
      "Epoch 713/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 121279912.0000 - mae: 8199.9883 - val_loss: 94263248.0000 - val_mae: 7374.2197\n",
      "Epoch 714/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 121166488.0000 - mae: 8198.6426 - val_loss: 94225288.0000 - val_mae: 7373.0337\n",
      "Epoch 715/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 121054352.0000 - mae: 8197.3232 - val_loss: 94186768.0000 - val_mae: 7371.8218\n",
      "Epoch 716/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 120941608.0000 - mae: 8195.8330 - val_loss: 94147368.0000 - val_mae: 7370.5405\n",
      "Epoch 717/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 120830272.0000 - mae: 8194.2490 - val_loss: 94107120.0000 - val_mae: 7370.0718\n",
      "Epoch 718/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 120720272.0000 - mae: 8192.5762 - val_loss: 94066040.0000 - val_mae: 7370.2881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 120611576.0000 - mae: 8190.8345 - val_loss: 94024288.0000 - val_mae: 7370.3789\n",
      "Epoch 720/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 120504200.0000 - mae: 8189.0171 - val_loss: 93981680.0000 - val_mae: 7370.3696\n",
      "Epoch 721/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 120397856.0000 - mae: 8187.1230 - val_loss: 93938248.0000 - val_mae: 7370.2612\n",
      "Epoch 722/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 120292512.0000 - mae: 8185.1538 - val_loss: 93894048.0000 - val_mae: 7370.0571\n",
      "Epoch 723/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 120188128.0000 - mae: 8183.1187 - val_loss: 93849104.0000 - val_mae: 7369.7622\n",
      "Epoch 724/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 120084568.0000 - mae: 8181.0195 - val_loss: 93803448.0000 - val_mae: 7369.3789\n",
      "Epoch 725/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 119981856.0000 - mae: 8178.8599 - val_loss: 93757104.0000 - val_mae: 7368.9092\n",
      "Epoch 726/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 119879904.0000 - mae: 8176.6377 - val_loss: 93710128.0000 - val_mae: 7368.3560\n",
      "Epoch 727/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 119778672.0000 - mae: 8174.3662 - val_loss: 93662512.0000 - val_mae: 7367.7197\n",
      "Epoch 728/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 119678160.0000 - mae: 8172.0498 - val_loss: 93613640.0000 - val_mae: 7366.9497\n",
      "Epoch 729/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 119578320.0000 - mae: 8169.6899 - val_loss: 93564184.0000 - val_mae: 7366.1016\n",
      "Epoch 730/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 119479024.0000 - mae: 8167.2827 - val_loss: 93513776.0000 - val_mae: 7365.1431\n",
      "Epoch 731/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 119380200.0000 - mae: 8164.8271 - val_loss: 93462896.0000 - val_mae: 7364.1182\n",
      "Epoch 732/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 119281936.0000 - mae: 8162.3408 - val_loss: 93411576.0000 - val_mae: 7363.0137\n",
      "Epoch 733/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 119184416.0000 - mae: 8159.8320 - val_loss: 93359400.0000 - val_mae: 7361.7944\n",
      "Epoch 734/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 119087256.0000 - mae: 8157.2715 - val_loss: 93306648.0000 - val_mae: 7360.5093\n",
      "Epoch 735/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118990576.0000 - mae: 8154.6748 - val_loss: 93253336.0000 - val_mae: 7359.1602\n",
      "Epoch 736/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118894168.0000 - mae: 8152.0308 - val_loss: 93199200.0000 - val_mae: 7357.7266\n",
      "Epoch 737/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 118797912.0000 - mae: 8149.3311 - val_loss: 93144504.0000 - val_mae: 7356.2300\n",
      "Epoch 738/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118702128.0000 - mae: 8146.6079 - val_loss: 93089240.0000 - val_mae: 7354.6714\n",
      "Epoch 739/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118606776.0000 - mae: 8143.8613 - val_loss: 93033360.0000 - val_mae: 7353.0464\n",
      "Epoch 740/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118511840.0000 - mae: 8141.0918 - val_loss: 92976816.0000 - val_mae: 7351.3545\n",
      "Epoch 741/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118417008.0000 - mae: 8138.2842 - val_loss: 92918456.0000 - val_mae: 7349.5425\n",
      "Epoch 742/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118322032.0000 - mae: 8135.4160 - val_loss: 92859624.0000 - val_mae: 7347.6714\n",
      "Epoch 743/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118227448.0000 - mae: 8132.5366 - val_loss: 92800152.0000 - val_mae: 7345.7334\n",
      "Epoch 744/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 118133208.0000 - mae: 8129.6353 - val_loss: 92739872.0000 - val_mae: 7343.7227\n",
      "Epoch 745/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 118039200.0000 - mae: 8126.7085 - val_loss: 92678752.0000 - val_mae: 7341.6304\n",
      "Epoch 746/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 117945264.0000 - mae: 8123.7563 - val_loss: 92616728.0000 - val_mae: 7339.4604\n",
      "Epoch 747/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 117851640.0000 - mae: 8120.7808 - val_loss: 92553720.0000 - val_mae: 7337.2080\n",
      "Epoch 748/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 117757976.0000 - mae: 8117.7544 - val_loss: 92488720.0000 - val_mae: 7334.8521\n",
      "Epoch 749/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 117663848.0000 - mae: 8114.6514 - val_loss: 92422928.0000 - val_mae: 7332.4106\n",
      "Epoch 750/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 117570016.0000 - mae: 8111.5488 - val_loss: 92356088.0000 - val_mae: 7329.8774\n",
      "Epoch 751/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 117476480.0000 - mae: 8108.4229 - val_loss: 92288128.0000 - val_mae: 7327.2515\n",
      "Epoch 752/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 117383120.0000 - mae: 8105.2710 - val_loss: 92218968.0000 - val_mae: 7324.5327\n",
      "Epoch 753/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 117289816.0000 - mae: 8102.0898 - val_loss: 92148640.0000 - val_mae: 7321.7129\n",
      "Epoch 754/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 117196368.0000 - mae: 8098.8765 - val_loss: 92077128.0000 - val_mae: 7318.7993\n",
      "Epoch 755/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 117103128.0000 - mae: 8095.6460 - val_loss: 92004488.0000 - val_mae: 7315.8047\n",
      "Epoch 756/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 117010120.0000 - mae: 8092.7798 - val_loss: 91930680.0000 - val_mae: 7312.7363\n",
      "Epoch 757/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116917176.0000 - mae: 8089.9448 - val_loss: 91855688.0000 - val_mae: 7309.5859\n",
      "Epoch 758/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116824296.0000 - mae: 8087.0767 - val_loss: 91779512.0000 - val_mae: 7306.3491\n",
      "Epoch 759/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116731432.0000 - mae: 8084.1753 - val_loss: 91702232.0000 - val_mae: 7303.0298\n",
      "Epoch 760/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 116638592.0000 - mae: 8081.2373 - val_loss: 91623808.0000 - val_mae: 7299.6274\n",
      "Epoch 761/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116545728.0000 - mae: 8078.2646 - val_loss: 91544360.0000 - val_mae: 7296.1509\n",
      "Epoch 762/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 116452872.0000 - mae: 8075.2612 - val_loss: 91463904.0000 - val_mae: 7292.6021\n",
      "Epoch 763/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116359984.0000 - mae: 8072.2261 - val_loss: 91382520.0000 - val_mae: 7288.9839\n",
      "Epoch 764/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116267088.0000 - mae: 8069.1636 - val_loss: 91300280.0000 - val_mae: 7285.3013\n",
      "Epoch 765/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116174176.0000 - mae: 8066.0718 - val_loss: 91217184.0000 - val_mae: 7281.5581\n",
      "Epoch 766/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 116081224.0000 - mae: 8062.9517 - val_loss: 91133336.0000 - val_mae: 7277.7578\n",
      "Epoch 767/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 115988240.0000 - mae: 8059.8057 - val_loss: 91048744.0000 - val_mae: 7273.9038\n",
      "Epoch 768/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 115895224.0000 - mae: 8056.6348 - val_loss: 90963560.0000 - val_mae: 7270.0010\n",
      "Epoch 769/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 115802200.0000 - mae: 8053.4390 - val_loss: 90877680.0000 - val_mae: 7266.0513\n",
      "Epoch 770/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 115709120.0000 - mae: 8050.2173 - val_loss: 90791400.0000 - val_mae: 7262.0654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 115616008.0000 - mae: 8046.9775 - val_loss: 90705000.0000 - val_mae: 7258.0928\n",
      "Epoch 772/1100\n",
      "102/102 [==============================] - 0s 78us/step - loss: 115522880.0000 - mae: 8043.7095 - val_loss: 90618368.0000 - val_mae: 7254.0894\n",
      "Epoch 773/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 115429720.0000 - mae: 8040.4277 - val_loss: 90530880.0000 - val_mae: 7250.0396\n",
      "Epoch 774/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 115336544.0000 - mae: 8037.1138 - val_loss: 90443792.0000 - val_mae: 7245.9785\n",
      "Epoch 775/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 115243336.0000 - mae: 8033.8037 - val_loss: 90354664.0000 - val_mae: 7241.8413\n",
      "Epoch 776/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 115150104.0000 - mae: 8030.4253 - val_loss: 90268848.0000 - val_mae: 7237.7681\n",
      "Epoch 777/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 115056824.0000 - mae: 8027.4497 - val_loss: 90173864.0000 - val_mae: 7233.4399\n",
      "Epoch 778/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 114963456.0000 - mae: 8024.1602 - val_loss: 90100024.0000 - val_mae: 7229.6265\n",
      "Epoch 779/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 114870104.0000 - mae: 8021.6362 - val_loss: 89970528.0000 - val_mae: 7224.3940\n",
      "Epoch 780/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 114776936.0000 - mae: 8017.0674 - val_loss: 89987280.0000 - val_mae: 7222.7378\n",
      "Epoch 781/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 114684904.0000 - mae: 8017.7378 - val_loss: 89653696.0000 - val_mae: 7212.2666\n",
      "Epoch 782/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 114597992.0000 - mae: 8005.5171 - val_loss: 89881072.0000 - val_mae: 7215.9990\n",
      "Epoch 783/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 114503656.0000 - mae: 8014.7515 - val_loss: 89516992.0000 - val_mae: 7205.0806\n",
      "Epoch 784/1100\n",
      "102/102 [==============================] - 0s 98us/step - loss: 114408024.0000 - mae: 8000.9717 - val_loss: 89605848.0000 - val_mae: 7205.3330\n",
      "Epoch 785/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 114312848.0000 - mae: 8004.7397 - val_loss: 89404256.0000 - val_mae: 7198.3535\n",
      "Epoch 786/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 114219312.0000 - mae: 7997.1675 - val_loss: 89387528.0000 - val_mae: 7195.8379\n",
      "Epoch 787/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 114126072.0000 - mae: 7997.0737 - val_loss: 89246000.0000 - val_mae: 7190.2773\n",
      "Epoch 788/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 114033072.0000 - mae: 7991.8706 - val_loss: 89195640.0000 - val_mae: 7186.8667\n",
      "Epoch 789/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 113939944.0000 - mae: 7990.4512 - val_loss: 89071232.0000 - val_mae: 7181.6675\n",
      "Epoch 790/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113846656.0000 - mae: 7985.9634 - val_loss: 89010816.0000 - val_mae: 7178.3848\n",
      "Epoch 791/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 113753360.0000 - mae: 7984.1055 - val_loss: 88889304.0000 - val_mae: 7173.6973\n",
      "Epoch 792/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113660112.0000 - mae: 7979.7275 - val_loss: 88830424.0000 - val_mae: 7171.2812\n",
      "Epoch 793/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113566864.0000 - mae: 7977.8965 - val_loss: 88701664.0000 - val_mae: 7166.3086\n",
      "Epoch 794/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113473656.0000 - mae: 7973.2158 - val_loss: 88655944.0000 - val_mae: 7164.3140\n",
      "Epoch 795/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113380496.0000 - mae: 7971.8779 - val_loss: 88504392.0000 - val_mae: 7158.5015\n",
      "Epoch 796/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113287440.0000 - mae: 7966.2715 - val_loss: 88494200.0000 - val_mae: 7157.7036\n",
      "Epoch 797/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113194496.0000 - mae: 7966.3013 - val_loss: 88287984.0000 - val_mae: 7149.9321\n",
      "Epoch 798/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113102064.0000 - mae: 7958.5005 - val_loss: 88350944.0000 - val_mae: 7151.7554\n",
      "Epoch 799/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 113009792.0000 - mae: 7961.3442 - val_loss: 88063168.0000 - val_mae: 7140.9976\n",
      "Epoch 800/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 112918160.0000 - mae: 7950.3203 - val_loss: 88182216.0000 - val_mae: 7145.5000\n",
      "Epoch 801/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 112825096.0000 - mae: 7955.5439 - val_loss: 87890328.0000 - val_mae: 7133.9731\n",
      "Epoch 802/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 112732208.0000 - mae: 7944.2783 - val_loss: 87968056.0000 - val_mae: 7136.5352\n",
      "Epoch 803/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 112638704.0000 - mae: 7947.6465 - val_loss: 87738760.0000 - val_mae: 7127.6357\n",
      "Epoch 804/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 112545832.0000 - mae: 7939.0503 - val_loss: 87759600.0000 - val_mae: 7127.8286\n",
      "Epoch 805/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 112453032.0000 - mae: 7940.1235 - val_loss: 87574296.0000 - val_mae: 7120.7339\n",
      "Epoch 806/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 112360736.0000 - mae: 7933.2451 - val_loss: 87566344.0000 - val_mae: 7119.9556\n",
      "Epoch 807/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 112268376.0000 - mae: 7933.5723 - val_loss: 87398104.0000 - val_mae: 7113.3535\n",
      "Epoch 808/1100\n",
      "102/102 [==============================] - 0s 147us/step - loss: 112176208.0000 - mae: 7927.1299 - val_loss: 87382592.0000 - val_mae: 7112.5962\n",
      "Epoch 809/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 112083936.0000 - mae: 7927.5073 - val_loss: 87212944.0000 - val_mae: 7105.6152\n",
      "Epoch 810/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 111991560.0000 - mae: 7921.0015 - val_loss: 87206272.0000 - val_mae: 7105.6396\n",
      "Epoch 811/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 111899176.0000 - mae: 7921.7090 - val_loss: 87019360.0000 - val_mae: 7097.5542\n",
      "Epoch 812/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 111807024.0000 - mae: 7914.4497 - val_loss: 87037664.0000 - val_mae: 7099.0669\n",
      "Epoch 813/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 111714864.0000 - mae: 7916.3032 - val_loss: 86818120.0000 - val_mae: 7089.2134\n",
      "Epoch 814/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 111623096.0000 - mae: 7907.5186 - val_loss: 86872296.0000 - val_mae: 7092.6362\n",
      "Epoch 815/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 111531120.0000 - mae: 7911.1104 - val_loss: 86619896.0000 - val_mae: 7080.9971\n",
      "Epoch 816/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 111439560.0000 - mae: 7900.6777 - val_loss: 86695064.0000 - val_mae: 7085.5098\n",
      "Epoch 817/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 111347472.0000 - mae: 7905.2363 - val_loss: 86439448.0000 - val_mae: 7073.3569\n",
      "Epoch 818/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 111255744.0000 - mae: 7894.6089 - val_loss: 86501832.0000 - val_mae: 7077.4697\n",
      "Epoch 819/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 111163576.0000 - mae: 7898.8721 - val_loss: 86269248.0000 - val_mae: 7066.0083\n",
      "Epoch 820/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 111071824.0000 - mae: 7889.0078 - val_loss: 86302992.0000 - val_mae: 7069.1455\n",
      "Epoch 821/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110979904.0000 - mae: 7892.4780 - val_loss: 86093296.0000 - val_mae: 7058.6997\n",
      "Epoch 822/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110888320.0000 - mae: 7883.2690 - val_loss: 86108912.0000 - val_mae: 7061.8833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110796568.0000 - mae: 7886.4067 - val_loss: 85911592.0000 - val_mae: 7051.3735\n",
      "Epoch 824/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110704800.0000 - mae: 7877.8291 - val_loss: 85921576.0000 - val_mae: 7055.6929\n",
      "Epoch 825/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110612984.0000 - mae: 7881.1079 - val_loss: 85722192.0000 - val_mae: 7044.1348\n",
      "Epoch 826/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 110521384.0000 - mae: 7872.2173 - val_loss: 85736896.0000 - val_mae: 7049.7529\n",
      "Epoch 827/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110429536.0000 - mae: 7876.3813 - val_loss: 85522192.0000 - val_mae: 7037.0991\n",
      "Epoch 828/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110337032.0000 - mae: 7866.6294 - val_loss: 85551232.0000 - val_mae: 7043.8271\n",
      "Epoch 829/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 110244520.0000 - mae: 7871.6860 - val_loss: 85320584.0000 - val_mae: 7029.9155\n",
      "Epoch 830/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110152440.0000 - mae: 7860.9155 - val_loss: 85365504.0000 - val_mae: 7037.8057\n",
      "Epoch 831/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 110060240.0000 - mae: 7866.8867 - val_loss: 85123992.0000 - val_mae: 7023.0703\n",
      "Epoch 832/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109968448.0000 - mae: 7855.3994 - val_loss: 85175664.0000 - val_mae: 7031.4199\n",
      "Epoch 833/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109876424.0000 - mae: 7861.6729 - val_loss: 84936152.0000 - val_mae: 7016.8979\n",
      "Epoch 834/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109784800.0000 - mae: 7850.2578 - val_loss: 84981464.0000 - val_mae: 7024.6592\n",
      "Epoch 835/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109692968.0000 - mae: 7856.0864 - val_loss: 84752688.0000 - val_mae: 7011.0029\n",
      "Epoch 836/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109601504.0000 - mae: 7845.3105 - val_loss: 84786608.0000 - val_mae: 7017.7578\n",
      "Epoch 837/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109509920.0000 - mae: 7850.4253 - val_loss: 84568488.0000 - val_mae: 7004.9429\n",
      "Epoch 838/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109418696.0000 - mae: 7840.2886 - val_loss: 84594592.0000 - val_mae: 7010.9971\n",
      "Epoch 839/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 109327368.0000 - mae: 7844.8950 - val_loss: 84381720.0000 - val_mae: 6998.6152\n",
      "Epoch 840/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109236368.0000 - mae: 7835.0547 - val_loss: 84406264.0000 - val_mae: 7004.4800\n",
      "Epoch 841/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 109144960.0000 - mae: 7839.5210 - val_loss: 84191840.0000 - val_mae: 6992.0200\n",
      "Epoch 842/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 109053904.0000 - mae: 7829.5576 - val_loss: 84221240.0000 - val_mae: 6998.1616\n",
      "Epoch 843/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108962776.0000 - mae: 7834.2686 - val_loss: 84000112.0000 - val_mae: 6985.2129\n",
      "Epoch 844/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108872024.0000 - mae: 7823.8877 - val_loss: 84037848.0000 - val_mae: 6991.8965\n",
      "Epoch 845/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108781144.0000 - mae: 7829.0459 - val_loss: 83808752.0000 - val_mae: 6978.3750\n",
      "Epoch 846/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 108690664.0000 - mae: 7818.1851 - val_loss: 83853688.0000 - val_mae: 6985.5146\n",
      "Epoch 847/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108599952.0000 - mae: 7823.6943 - val_loss: 83619920.0000 - val_mae: 6971.6431\n",
      "Epoch 848/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108509464.0000 - mae: 7812.5356 - val_loss: 83666296.0000 - val_mae: 6978.7773\n",
      "Epoch 849/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108418808.0000 - mae: 7818.0483 - val_loss: 83434256.0000 - val_mae: 6965.0845\n",
      "Epoch 850/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 108328568.0000 - mae: 7806.9756 - val_loss: 83477920.0000 - val_mae: 6971.9365\n",
      "Epoch 851/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 108238168.0000 - mae: 7812.2563 - val_loss: 83251072.0000 - val_mae: 6958.6699\n",
      "Epoch 852/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 108148120.0000 - mae: 7801.4731 - val_loss: 83290120.0000 - val_mae: 6965.0938\n",
      "Epoch 853/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 108057928.0000 - mae: 7806.4160 - val_loss: 83068056.0000 - val_mae: 6952.2266\n",
      "Epoch 854/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 107967720.0000 - mae: 7795.8916 - val_loss: 83100456.0000 - val_mae: 6958.1553\n",
      "Epoch 855/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 107874736.0000 - mae: 7800.3315 - val_loss: 82880696.0000 - val_mae: 6945.5303\n",
      "Epoch 856/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 107782488.0000 - mae: 7789.9141 - val_loss: 82914264.0000 - val_mae: 6951.4385\n",
      "Epoch 857/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 107689736.0000 - mae: 7794.2256 - val_loss: 82691480.0000 - val_mae: 6938.6548\n",
      "Epoch 858/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 107596768.0000 - mae: 7783.6592 - val_loss: 82728464.0000 - val_mae: 6944.7593\n",
      "Epoch 859/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 107503984.0000 - mae: 7788.1001 - val_loss: 82502864.0000 - val_mae: 6931.7842\n",
      "Epoch 860/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 107411696.0000 - mae: 7777.3789 - val_loss: 82543856.0000 - val_mae: 6938.0732\n",
      "Epoch 861/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 107318984.0000 - mae: 7781.9453 - val_loss: 82313200.0000 - val_mae: 6924.7578\n",
      "Epoch 862/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 107226904.0000 - mae: 7771.0415 - val_loss: 82357376.0000 - val_mae: 6931.1865\n",
      "Epoch 863/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 107134896.0000 - mae: 7775.7202 - val_loss: 82124752.0000 - val_mae: 6917.8154\n",
      "Epoch 864/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 107042960.0000 - mae: 7764.7549 - val_loss: 82169064.0000 - val_mae: 6924.2173\n",
      "Epoch 865/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106951008.0000 - mae: 7769.3467 - val_loss: 81938000.0000 - val_mae: 6910.9702\n",
      "Epoch 866/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106859592.0000 - mae: 7758.4985 - val_loss: 81980984.0000 - val_mae: 6917.1777\n",
      "Epoch 867/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106768152.0000 - mae: 7762.9204 - val_loss: 81752768.0000 - val_mae: 6904.1479\n",
      "Epoch 868/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 106677224.0000 - mae: 7752.2622 - val_loss: 81794008.0000 - val_mae: 6910.1357\n",
      "Epoch 869/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106586240.0000 - mae: 7756.4976 - val_loss: 81568048.0000 - val_mae: 6897.2925\n",
      "Epoch 870/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 106495728.0000 - mae: 7745.9976 - val_loss: 81608424.0000 - val_mae: 6903.1235\n",
      "Epoch 871/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 106405168.0000 - mae: 7750.0967 - val_loss: 81383136.0000 - val_mae: 6890.3423\n",
      "Epoch 872/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106315064.0000 - mae: 7739.6680 - val_loss: 81424592.0000 - val_mae: 6896.1562\n",
      "Epoch 873/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106224864.0000 - mae: 7743.7324 - val_loss: 81198352.0000 - val_mae: 6883.3291\n",
      "Epoch 874/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106135088.0000 - mae: 7733.2773 - val_loss: 81242112.0000 - val_mae: 6889.2051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 106045240.0000 - mae: 7737.3652 - val_loss: 81014056.0000 - val_mae: 6876.2651\n",
      "Epoch 876/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 105955816.0000 - mae: 7726.8452 - val_loss: 81060480.0000 - val_mae: 6882.2319\n",
      "Epoch 877/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105866304.0000 - mae: 7730.9756 - val_loss: 80831000.0000 - val_mae: 6869.2144\n",
      "Epoch 878/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105777184.0000 - mae: 7720.4062 - val_loss: 80879128.0000 - val_mae: 6875.2007\n",
      "Epoch 879/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105687960.0000 - mae: 7724.5220 - val_loss: 80649440.0000 - val_mae: 6862.1831\n",
      "Epoch 880/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105599128.0000 - mae: 7713.9692 - val_loss: 80697968.0000 - val_mae: 6868.0996\n",
      "Epoch 881/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105510200.0000 - mae: 7718.0088 - val_loss: 80466968.0000 - val_mae: 6855.0586\n",
      "Epoch 882/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 105420728.0000 - mae: 7707.4521 - val_loss: 80513832.0000 - val_mae: 6860.8169\n",
      "Epoch 883/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 105331240.0000 - mae: 7711.3062 - val_loss: 80286008.0000 - val_mae: 6847.9956\n",
      "Epoch 884/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105242280.0000 - mae: 7700.9473 - val_loss: 80331640.0000 - val_mae: 6853.5718\n",
      "Epoch 885/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105153264.0000 - mae: 7704.6206 - val_loss: 80106080.0000 - val_mae: 6840.9092\n",
      "Epoch 886/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 105064712.0000 - mae: 7694.4199 - val_loss: 80151392.0000 - val_mae: 6846.3760\n",
      "Epoch 887/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104976080.0000 - mae: 7697.9780 - val_loss: 79926464.0000 - val_mae: 6833.7715\n",
      "Epoch 888/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104887888.0000 - mae: 7687.8438 - val_loss: 79972744.0000 - val_mae: 6839.2075\n",
      "Epoch 889/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104799632.0000 - mae: 7691.3555 - val_loss: 79746872.0000 - val_mae: 6826.5542\n",
      "Epoch 890/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104711720.0000 - mae: 7681.1963 - val_loss: 79794768.0000 - val_mae: 6832.0098\n",
      "Epoch 891/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 104623680.0000 - mae: 7684.6890 - val_loss: 79567200.0000 - val_mae: 6819.2700\n",
      "Epoch 892/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104536072.0000 - mae: 7674.4888 - val_loss: 79617376.0000 - val_mae: 6824.7905\n",
      "Epoch 893/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 104448360.0000 - mae: 7678.0015 - val_loss: 79388440.0000 - val_mae: 6811.9766\n",
      "Epoch 894/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104360896.0000 - mae: 7667.8887 - val_loss: 79440280.0000 - val_mae: 6817.5137\n",
      "Epoch 895/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104272944.0000 - mae: 7671.1836 - val_loss: 79211424.0000 - val_mae: 6804.7212\n",
      "Epoch 896/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104185464.0000 - mae: 7661.3926 - val_loss: 79263288.0000 - val_mae: 6810.1753\n",
      "Epoch 897/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 104097864.0000 - mae: 7664.2925 - val_loss: 79034864.0000 - val_mae: 6797.4434\n",
      "Epoch 898/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 104010544.0000 - mae: 7654.8711 - val_loss: 79086008.0000 - val_mae: 6802.7759\n",
      "Epoch 899/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 103923152.0000 - mae: 7657.6421 - val_loss: 78858624.0000 - val_mae: 6790.1304\n",
      "Epoch 900/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 103836208.0000 - mae: 7648.3081 - val_loss: 78909232.0000 - val_mae: 6795.3477\n",
      "Epoch 901/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 103749208.0000 - mae: 7650.9780 - val_loss: 78682672.0000 - val_mae: 6782.7798\n",
      "Epoch 902/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 103662672.0000 - mae: 7641.7119 - val_loss: 78733296.0000 - val_mae: 6787.9185\n",
      "Epoch 903/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 103576056.0000 - mae: 7644.4644 - val_loss: 78506864.0000 - val_mae: 6775.3843\n",
      "Epoch 904/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 103489880.0000 - mae: 7635.0737 - val_loss: 78558208.0000 - val_mae: 6780.4907\n",
      "Epoch 905/1100\n",
      "102/102 [==============================] - 0s 88us/step - loss: 103403632.0000 - mae: 7638.4326 - val_loss: 78331272.0000 - val_mae: 6767.9497\n",
      "Epoch 906/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 103317824.0000 - mae: 7628.4834 - val_loss: 78383808.0000 - val_mae: 6773.0601\n",
      "Epoch 907/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 103231960.0000 - mae: 7632.3887 - val_loss: 78156176.0000 - val_mae: 6760.5029\n",
      "Epoch 908/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 103146520.0000 - mae: 7622.4214 - val_loss: 78209824.0000 - val_mae: 6765.6045\n",
      "Epoch 909/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 103060992.0000 - mae: 7626.2959 - val_loss: 77981752.0000 - val_mae: 6753.0464\n",
      "Epoch 910/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 102975888.0000 - mae: 7616.3237 - val_loss: 78036096.0000 - val_mae: 6758.1191\n",
      "Epoch 911/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 102890720.0000 - mae: 7620.1636 - val_loss: 77808360.0000 - val_mae: 6745.6060\n",
      "Epoch 912/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 102805992.0000 - mae: 7610.2217 - val_loss: 77863000.0000 - val_mae: 6750.6235\n",
      "Epoch 913/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 102720976.0000 - mae: 7613.9731 - val_loss: 77635720.0000 - val_mae: 6738.1777\n",
      "Epoch 914/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 102635944.0000 - mae: 7604.0259 - val_loss: 77690328.0000 - val_mae: 6743.1343\n",
      "Epoch 915/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 102550880.0000 - mae: 7607.6758 - val_loss: 77463736.0000 - val_mae: 6730.7485\n",
      "Epoch 916/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 102466288.0000 - mae: 7597.7832 - val_loss: 77518096.0000 - val_mae: 6735.6113\n",
      "Epoch 917/1100\n",
      "102/102 [==============================] - 0s 69us/step - loss: 102381648.0000 - mae: 7601.3511 - val_loss: 77292096.0000 - val_mae: 6723.2822\n",
      "Epoch 918/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 102297456.0000 - mae: 7591.5117 - val_loss: 77346464.0000 - val_mae: 6728.0693\n",
      "Epoch 919/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 102213032.0000 - mae: 7594.9888 - val_loss: 77120288.0000 - val_mae: 6715.7666\n",
      "Epoch 920/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 102128672.0000 - mae: 7585.1099 - val_loss: 77175024.0000 - val_mae: 6720.5229\n",
      "Epoch 921/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 102044320.0000 - mae: 7588.5166 - val_loss: 76949032.0000 - val_mae: 6708.2295\n",
      "Epoch 922/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101960384.0000 - mae: 7578.6460 - val_loss: 77004168.0000 - val_mae: 6712.9390\n",
      "Epoch 923/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101876272.0000 - mae: 7581.9756 - val_loss: 76778256.0000 - val_mae: 6700.6699\n",
      "Epoch 924/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101792640.0000 - mae: 7572.1211 - val_loss: 76833152.0000 - val_mae: 6705.3291\n",
      "Epoch 925/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 101708632.0000 - mae: 7575.3301 - val_loss: 76606928.0000 - val_mae: 6693.0757\n",
      "Epoch 926/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 101624760.0000 - mae: 7565.4360 - val_loss: 76661408.0000 - val_mae: 6697.5967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101540896.0000 - mae: 7568.5850 - val_loss: 76434488.0000 - val_mae: 6685.2788\n",
      "Epoch 928/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 101457376.0000 - mae: 7558.6997 - val_loss: 76488888.0000 - val_mae: 6689.7256\n",
      "Epoch 929/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101373888.0000 - mae: 7561.7700 - val_loss: 76262216.0000 - val_mae: 6677.4321\n",
      "Epoch 930/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101290816.0000 - mae: 7551.9248 - val_loss: 76316176.0000 - val_mae: 6681.8340\n",
      "Epoch 931/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101207408.0000 - mae: 7554.9229 - val_loss: 76089384.0000 - val_mae: 6669.5830\n",
      "Epoch 932/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 101124264.0000 - mae: 7545.1025 - val_loss: 76139320.0000 - val_mae: 6673.6641\n",
      "Epoch 933/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 101037280.0000 - mae: 7547.7744 - val_loss: 75910864.0000 - val_mae: 6661.3257\n",
      "Epoch 934/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 100951224.0000 - mae: 7537.9126 - val_loss: 75963152.0000 - val_mae: 6665.4673\n",
      "Epoch 935/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 100865496.0000 - mae: 7540.5620 - val_loss: 75735864.0000 - val_mae: 6653.2007\n",
      "Epoch 936/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100780464.0000 - mae: 7530.7866 - val_loss: 75789584.0000 - val_mae: 6657.3574\n",
      "Epoch 937/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100695544.0000 - mae: 7533.3926 - val_loss: 75562744.0000 - val_mae: 6645.1226\n",
      "Epoch 938/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100611256.0000 - mae: 7523.6655 - val_loss: 75617600.0000 - val_mae: 6649.2720\n",
      "Epoch 939/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100527000.0000 - mae: 7526.2305 - val_loss: 75391024.0000 - val_mae: 6637.0566\n",
      "Epoch 940/1100\n",
      "102/102 [==============================] - 0s 59us/step - loss: 100443296.0000 - mae: 7516.5352 - val_loss: 75446544.0000 - val_mae: 6641.1655\n",
      "Epoch 941/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100359608.0000 - mae: 7519.0249 - val_loss: 75220352.0000 - val_mae: 6628.9702\n",
      "Epoch 942/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 100276448.0000 - mae: 7509.3677 - val_loss: 75276280.0000 - val_mae: 6633.0269\n",
      "Epoch 943/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100193256.0000 - mae: 7511.7783 - val_loss: 75050640.0000 - val_mae: 6620.8613\n",
      "Epoch 944/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100110560.0000 - mae: 7502.1631 - val_loss: 75106880.0000 - val_mae: 6624.8545\n",
      "Epoch 945/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 100027832.0000 - mae: 7504.4873 - val_loss: 74881752.0000 - val_mae: 6612.7163\n",
      "Epoch 946/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99945616.0000 - mae: 7494.9131 - val_loss: 74938352.0000 - val_mae: 6616.6523\n",
      "Epoch 947/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99863344.0000 - mae: 7497.1655 - val_loss: 74713616.0000 - val_mae: 6604.5327\n",
      "Epoch 948/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99781512.0000 - mae: 7487.6255 - val_loss: 74770640.0000 - val_mae: 6608.4185\n",
      "Epoch 949/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 99699640.0000 - mae: 7489.8223 - val_loss: 74545864.0000 - val_mae: 6596.2856\n",
      "Epoch 950/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 99618256.0000 - mae: 7480.3071 - val_loss: 74603336.0000 - val_mae: 6600.1006\n",
      "Epoch 951/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99536792.0000 - mae: 7482.4541 - val_loss: 74378672.0000 - val_mae: 6587.9712\n",
      "Epoch 952/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99455632.0000 - mae: 7472.9224 - val_loss: 74436824.0000 - val_mae: 6591.7456\n",
      "Epoch 953/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99374240.0000 - mae: 7474.9888 - val_loss: 74212296.0000 - val_mae: 6579.6221\n",
      "Epoch 954/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99293328.0000 - mae: 7465.4497 - val_loss: 74271072.0000 - val_mae: 6583.3535\n",
      "Epoch 955/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99212360.0000 - mae: 7467.4683 - val_loss: 74046720.0000 - val_mae: 6571.2388\n",
      "Epoch 956/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 99131872.0000 - mae: 7457.9473 - val_loss: 74106056.0000 - val_mae: 6574.9238\n",
      "Epoch 957/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 99051248.0000 - mae: 7459.8584 - val_loss: 73881816.0000 - val_mae: 6562.8149\n",
      "Epoch 958/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98971032.0000 - mae: 7450.2646 - val_loss: 73941648.0000 - val_mae: 6566.4526\n",
      "Epoch 959/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 98890752.0000 - mae: 7452.1040 - val_loss: 73717672.0000 - val_mae: 6554.3545\n",
      "Epoch 960/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98810992.0000 - mae: 7442.6025 - val_loss: 73778336.0000 - val_mae: 6557.9282\n",
      "Epoch 961/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 98731440.0000 - mae: 7444.5068 - val_loss: 73555448.0000 - val_mae: 6545.8740\n",
      "Epoch 962/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 98652304.0000 - mae: 7435.0537 - val_loss: 73616208.0000 - val_mae: 6549.9673\n",
      "Epoch 963/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 98573080.0000 - mae: 7436.8525 - val_loss: 73393648.0000 - val_mae: 6537.3696\n",
      "Epoch 964/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98493888.0000 - mae: 7427.3745 - val_loss: 73455136.0000 - val_mae: 6543.1235\n",
      "Epoch 965/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98413104.0000 - mae: 7429.0513 - val_loss: 73233632.0000 - val_mae: 6528.6753\n",
      "Epoch 966/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 98333104.0000 - mae: 7419.5654 - val_loss: 73295200.0000 - val_mae: 6536.2075\n",
      "Epoch 967/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98253120.0000 - mae: 7421.1523 - val_loss: 73073936.0000 - val_mae: 6520.7744\n",
      "Epoch 968/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98173568.0000 - mae: 7411.6655 - val_loss: 73135568.0000 - val_mae: 6529.2036\n",
      "Epoch 969/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98094040.0000 - mae: 7413.1787 - val_loss: 72914232.0000 - val_mae: 6513.7871\n",
      "Epoch 970/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 98014992.0000 - mae: 7403.7134 - val_loss: 72975384.0000 - val_mae: 6522.1455\n",
      "Epoch 971/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97935632.0000 - mae: 7405.1372 - val_loss: 72754672.0000 - val_mae: 6506.7456\n",
      "Epoch 972/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 97856272.0000 - mae: 7395.5962 - val_loss: 72816848.0000 - val_mae: 6515.0459\n",
      "Epoch 973/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97777584.0000 - mae: 7396.8901 - val_loss: 72597272.0000 - val_mae: 6499.6987\n",
      "Epoch 974/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97699432.0000 - mae: 7387.4136 - val_loss: 72659760.0000 - val_mae: 6508.0054\n",
      "Epoch 975/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97621296.0000 - mae: 7388.6904 - val_loss: 72441216.0000 - val_mae: 6492.7422\n",
      "Epoch 976/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97543608.0000 - mae: 7379.2568 - val_loss: 72503984.0000 - val_mae: 6501.0259\n",
      "Epoch 977/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97465880.0000 - mae: 7380.4814 - val_loss: 72286680.0000 - val_mae: 6485.8789\n",
      "Epoch 978/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97388552.0000 - mae: 7371.0796 - val_loss: 72350312.0000 - val_mae: 6494.2402\n",
      "Epoch 979/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 97311536.0000 - mae: 7372.6997 - val_loss: 72135112.0000 - val_mae: 6479.2363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97235296.0000 - mae: 7362.8872 - val_loss: 72199640.0000 - val_mae: 6487.5703\n",
      "Epoch 981/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 97159000.0000 - mae: 7365.2637 - val_loss: 71985416.0000 - val_mae: 6472.6382\n",
      "Epoch 982/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 97083048.0000 - mae: 7355.2734 - val_loss: 72050416.0000 - val_mae: 6480.9702\n",
      "Epoch 983/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 97007024.0000 - mae: 7357.8320 - val_loss: 71836768.0000 - val_mae: 6466.0732\n",
      "Epoch 984/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96931336.0000 - mae: 7347.8511 - val_loss: 71902600.0000 - val_mae: 6474.3970\n",
      "Epoch 985/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96855584.0000 - mae: 7350.3623 - val_loss: 71689056.0000 - val_mae: 6459.5283\n",
      "Epoch 986/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96780184.0000 - mae: 7340.4048 - val_loss: 71755136.0000 - val_mae: 6467.8286\n",
      "Epoch 987/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96704696.0000 - mae: 7342.8623 - val_loss: 71542136.0000 - val_mae: 6452.9868\n",
      "Epoch 988/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 96629608.0000 - mae: 7332.9302 - val_loss: 71608400.0000 - val_mae: 6461.2554\n",
      "Epoch 989/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 96554408.0000 - mae: 7335.3462 - val_loss: 71396496.0000 - val_mae: 6446.4390\n",
      "Epoch 990/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96479600.0000 - mae: 7325.4321 - val_loss: 71462272.0000 - val_mae: 6454.6641\n",
      "Epoch 991/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 96404672.0000 - mae: 7327.7832 - val_loss: 71250912.0000 - val_mae: 6439.8643\n",
      "Epoch 992/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96330152.0000 - mae: 7317.8848 - val_loss: 71316752.0000 - val_mae: 6448.0459\n",
      "Epoch 993/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 96255552.0000 - mae: 7320.1826 - val_loss: 71105968.0000 - val_mae: 6433.2607\n",
      "Epoch 994/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96181248.0000 - mae: 7310.2935 - val_loss: 71171640.0000 - val_mae: 6441.3262\n",
      "Epoch 995/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 96106584.0000 - mae: 7312.4536 - val_loss: 70960704.0000 - val_mae: 6426.5391\n",
      "Epoch 996/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 96032368.0000 - mae: 7302.5762 - val_loss: 71026528.0000 - val_mae: 6434.5513\n",
      "Epoch 997/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95957912.0000 - mae: 7304.6440 - val_loss: 70816208.0000 - val_mae: 6419.7856\n",
      "Epoch 998/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95883888.0000 - mae: 7294.7471 - val_loss: 70882096.0000 - val_mae: 6427.7690\n",
      "Epoch 999/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95809840.0000 - mae: 7296.7700 - val_loss: 70672544.0000 - val_mae: 6412.9766\n",
      "Epoch 1000/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95736280.0000 - mae: 7286.9023 - val_loss: 70738616.0000 - val_mae: 6420.9268\n",
      "Epoch 1001/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95662712.0000 - mae: 7289.3862 - val_loss: 70529312.0000 - val_mae: 6406.1138\n",
      "Epoch 1002/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 95589704.0000 - mae: 7279.0645 - val_loss: 70595168.0000 - val_mae: 6414.0615\n",
      "Epoch 1003/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 95516608.0000 - mae: 7282.2500 - val_loss: 70386032.0000 - val_mae: 6399.2134\n",
      "Epoch 1004/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 95443728.0000 - mae: 7271.1992 - val_loss: 70451984.0000 - val_mae: 6407.0737\n",
      "Epoch 1005/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 95369704.0000 - mae: 7274.9307 - val_loss: 70243400.0000 - val_mae: 6392.2437\n",
      "Epoch 1006/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 95296992.0000 - mae: 7263.4922 - val_loss: 70312280.0000 - val_mae: 6400.1206\n",
      "Epoch 1007/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95226528.0000 - mae: 7267.9302 - val_loss: 70111552.0000 - val_mae: 6385.5488\n",
      "Epoch 1008/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95159656.0000 - mae: 7256.3423 - val_loss: 70183312.0000 - val_mae: 6393.4448\n",
      "Epoch 1009/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 95092656.0000 - mae: 7261.3457 - val_loss: 69980224.0000 - val_mae: 6378.7275\n",
      "Epoch 1010/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 95025752.0000 - mae: 7249.3340 - val_loss: 70050776.0000 - val_mae: 6386.5322\n",
      "Epoch 1011/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94957936.0000 - mae: 7255.1655 - val_loss: 69847120.0000 - val_mae: 6371.6729\n",
      "Epoch 1012/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94890576.0000 - mae: 7242.6001 - val_loss: 69917984.0000 - val_mae: 6379.5581\n",
      "Epoch 1013/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94823144.0000 - mae: 7249.0249 - val_loss: 69713168.0000 - val_mae: 6364.5493\n",
      "Epoch 1014/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94756112.0000 - mae: 7236.3877 - val_loss: 69785216.0000 - val_mae: 6373.6807\n",
      "Epoch 1015/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 94689000.0000 - mae: 7242.8477 - val_loss: 69580280.0000 - val_mae: 6357.3916\n",
      "Epoch 1016/1100\n",
      "102/102 [==============================] - 0s 127us/step - loss: 94622080.0000 - mae: 7230.1050 - val_loss: 69653776.0000 - val_mae: 6368.2490\n",
      "Epoch 1017/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 94555144.0000 - mae: 7236.4717 - val_loss: 69449088.0000 - val_mae: 6350.5049\n",
      "Epoch 1018/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94488616.0000 - mae: 7223.8247 - val_loss: 69521240.0000 - val_mae: 6362.7549\n",
      "Epoch 1019/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94422536.0000 - mae: 7230.1084 - val_loss: 69323144.0000 - val_mae: 6345.4248\n",
      "Epoch 1020/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 94357904.0000 - mae: 7217.7109 - val_loss: 69396184.0000 - val_mae: 6357.5312\n",
      "Epoch 1021/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94293224.0000 - mae: 7224.2832 - val_loss: 69198824.0000 - val_mae: 6340.2109\n",
      "Epoch 1022/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94228944.0000 - mae: 7211.5654 - val_loss: 69272016.0000 - val_mae: 6352.3169\n",
      "Epoch 1023/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 94164600.0000 - mae: 7218.9180 - val_loss: 69074168.0000 - val_mae: 6334.8569\n",
      "Epoch 1024/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 94100728.0000 - mae: 7205.9878 - val_loss: 69148720.0000 - val_mae: 6347.0928\n",
      "Epoch 1025/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 94036808.0000 - mae: 7214.2988 - val_loss: 68950264.0000 - val_mae: 6329.4565\n",
      "Epoch 1026/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93973496.0000 - mae: 7201.2168 - val_loss: 69026888.0000 - val_mae: 6341.8608\n",
      "Epoch 1027/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93910160.0000 - mae: 7209.6304 - val_loss: 68827648.0000 - val_mae: 6324.0410\n",
      "Epoch 1028/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 93847200.0000 - mae: 7196.4346 - val_loss: 68903864.0000 - val_mae: 6336.5815\n",
      "Epoch 1029/1100\n",
      "102/102 [==============================] - 0s 137us/step - loss: 93784192.0000 - mae: 7204.9644 - val_loss: 68704528.0000 - val_mae: 6318.6445\n",
      "Epoch 1030/1100\n",
      "102/102 [==============================] - 0s 196us/step - loss: 93721640.0000 - mae: 7191.6758 - val_loss: 68781240.0000 - val_mae: 6331.0762\n",
      "Epoch 1031/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93659088.0000 - mae: 7200.2134 - val_loss: 68582408.0000 - val_mae: 6313.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1032/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93596872.0000 - mae: 7186.9570 - val_loss: 68656536.0000 - val_mae: 6325.4849\n",
      "Epoch 1033/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93534576.0000 - mae: 7196.3037 - val_loss: 68459760.0000 - val_mae: 6307.6729\n",
      "Epoch 1034/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93472696.0000 - mae: 7182.2236 - val_loss: 68533152.0000 - val_mae: 6319.8530\n",
      "Epoch 1035/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93410848.0000 - mae: 7192.6060 - val_loss: 68339824.0000 - val_mae: 6302.0576\n",
      "Epoch 1036/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93349408.0000 - mae: 7178.4429 - val_loss: 68413360.0000 - val_mae: 6314.1943\n",
      "Epoch 1037/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 93287968.0000 - mae: 7188.9307 - val_loss: 68219288.0000 - val_mae: 6296.4121\n",
      "Epoch 1038/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 93227232.0000 - mae: 7174.7515 - val_loss: 68298440.0000 - val_mae: 6308.4844\n",
      "Epoch 1039/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 93167392.0000 - mae: 7185.2964 - val_loss: 68109952.0000 - val_mae: 6290.6274\n",
      "Epoch 1040/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 93108016.0000 - mae: 7171.2324 - val_loss: 68189304.0000 - val_mae: 6302.7646\n",
      "Epoch 1041/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 93048584.0000 - mae: 7181.6558 - val_loss: 68000864.0000 - val_mae: 6284.8882\n",
      "Epoch 1042/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92989632.0000 - mae: 7167.7026 - val_loss: 68080624.0000 - val_mae: 6297.0581\n",
      "Epoch 1043/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 92930768.0000 - mae: 7178.1724 - val_loss: 67895128.0000 - val_mae: 6279.2759\n",
      "Epoch 1044/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 92872576.0000 - mae: 7164.3032 - val_loss: 67976168.0000 - val_mae: 6291.5391\n",
      "Epoch 1045/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 92814360.0000 - mae: 7174.7363 - val_loss: 67790224.0000 - val_mae: 6273.8945\n",
      "Epoch 1046/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92756256.0000 - mae: 7160.7300 - val_loss: 67859488.0000 - val_mae: 6285.8198\n",
      "Epoch 1047/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92695016.0000 - mae: 7170.6499 - val_loss: 67670320.0000 - val_mae: 6268.4976\n",
      "Epoch 1048/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 92634688.0000 - mae: 7156.6377 - val_loss: 67744352.0000 - val_mae: 6280.7651\n",
      "Epoch 1049/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92574648.0000 - mae: 7166.7358 - val_loss: 67555872.0000 - val_mae: 6263.2603\n",
      "Epoch 1050/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92515136.0000 - mae: 7152.6006 - val_loss: 67630832.0000 - val_mae: 6275.5840\n",
      "Epoch 1051/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92455704.0000 - mae: 7162.7539 - val_loss: 67442248.0000 - val_mae: 6257.9404\n",
      "Epoch 1052/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 92396896.0000 - mae: 7148.5117 - val_loss: 67518432.0000 - val_mae: 6270.3481\n",
      "Epoch 1053/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92338136.0000 - mae: 7158.7158 - val_loss: 67330344.0000 - val_mae: 6252.6240\n",
      "Epoch 1054/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92279680.0000 - mae: 7144.4321 - val_loss: 67406320.0000 - val_mae: 6264.9683\n",
      "Epoch 1055/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 92221296.0000 - mae: 7154.5952 - val_loss: 67219864.0000 - val_mae: 6247.3081\n",
      "Epoch 1056/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 92163504.0000 - mae: 7140.3384 - val_loss: 67295528.0000 - val_mae: 6259.5708\n",
      "Epoch 1057/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 92105968.0000 - mae: 7150.4668 - val_loss: 67113240.0000 - val_mae: 6242.0503\n",
      "Epoch 1058/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 92049512.0000 - mae: 7136.4360 - val_loss: 67189224.0000 - val_mae: 6254.1011\n",
      "Epoch 1059/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 91993120.0000 - mae: 7146.4570 - val_loss: 67007800.0000 - val_mae: 6236.6064\n",
      "Epoch 1060/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91937272.0000 - mae: 7132.4229 - val_loss: 67084620.0000 - val_mae: 6248.7349\n",
      "Epoch 1061/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91881448.0000 - mae: 7142.4731 - val_loss: 66903328.0000 - val_mae: 6231.1685\n",
      "Epoch 1062/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91826136.0000 - mae: 7128.3457 - val_loss: 66981296.0000 - val_mae: 6243.3975\n",
      "Epoch 1063/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 91770840.0000 - mae: 7138.4561 - val_loss: 66799948.0000 - val_mae: 6225.7231\n",
      "Epoch 1064/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91716120.0000 - mae: 7124.2451 - val_loss: 66879376.0000 - val_mae: 6238.0718\n",
      "Epoch 1065/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91661192.0000 - mae: 7134.5142 - val_loss: 66698352.0000 - val_mae: 6220.3369\n",
      "Epoch 1066/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91606816.0000 - mae: 7120.1030 - val_loss: 66778604.0000 - val_mae: 6232.7236\n",
      "Epoch 1067/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 91552568.0000 - mae: 7130.8623 - val_loss: 66598500.0000 - val_mae: 6214.9854\n",
      "Epoch 1068/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91498768.0000 - mae: 7115.9956 - val_loss: 66678972.0000 - val_mae: 6227.3379\n",
      "Epoch 1069/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91445008.0000 - mae: 7127.1616 - val_loss: 66499472.0000 - val_mae: 6209.6118\n",
      "Epoch 1070/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 91391840.0000 - mae: 7112.2974 - val_loss: 66578800.0000 - val_mae: 6221.8374\n",
      "Epoch 1071/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91338672.0000 - mae: 7123.4468 - val_loss: 66400108.0000 - val_mae: 6204.1294\n",
      "Epoch 1072/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91285992.0000 - mae: 7108.6050 - val_loss: 66479672.0000 - val_mae: 6217.3242\n",
      "Epoch 1073/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91233384.0000 - mae: 7119.6973 - val_loss: 66302364.0000 - val_mae: 6198.6572\n",
      "Epoch 1074/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91181320.0000 - mae: 7104.8911 - val_loss: 66382344.0000 - val_mae: 6214.1782\n",
      "Epoch 1075/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91129216.0000 - mae: 7115.9497 - val_loss: 66205960.0000 - val_mae: 6193.2524\n",
      "Epoch 1076/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 91077664.0000 - mae: 7101.1152 - val_loss: 66286980.0000 - val_mae: 6211.0820\n",
      "Epoch 1077/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 91026168.0000 - mae: 7112.2109 - val_loss: 66111088.0000 - val_mae: 6190.0513\n",
      "Epoch 1078/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90975160.0000 - mae: 7097.3125 - val_loss: 66192788.0000 - val_mae: 6207.9976\n",
      "Epoch 1079/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90924464.0000 - mae: 7108.4668 - val_loss: 66016968.0000 - val_mae: 6186.8667\n",
      "Epoch 1080/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90874336.0000 - mae: 7093.5269 - val_loss: 66099736.0000 - val_mae: 6204.8872\n",
      "Epoch 1081/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 90824120.0000 - mae: 7104.6963 - val_loss: 65924700.0000 - val_mae: 6183.6919\n",
      "Epoch 1082/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 90774456.0000 - mae: 7089.7124 - val_loss: 66008420.0000 - val_mae: 6201.7754\n",
      "Epoch 1083/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90724872.0000 - mae: 7100.9082 - val_loss: 65834644.0000 - val_mae: 6180.5376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1084/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90676040.0000 - mae: 7085.9536 - val_loss: 65919964.0000 - val_mae: 6198.6782\n",
      "Epoch 1085/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 90627384.0000 - mae: 7097.1826 - val_loss: 65747912.0000 - val_mae: 6177.4604\n",
      "Epoch 1086/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 90579288.0000 - mae: 7082.2251 - val_loss: 65830420.0000 - val_mae: 6195.5098\n",
      "Epoch 1087/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90531136.0000 - mae: 7093.3438 - val_loss: 65659204.0000 - val_mae: 6174.2373\n",
      "Epoch 1088/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 90483560.0000 - mae: 7078.3462 - val_loss: 65742372.0000 - val_mae: 6192.2837\n",
      "Epoch 1089/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 90435936.0000 - mae: 7089.4565 - val_loss: 65572152.0000 - val_mae: 6170.9941\n",
      "Epoch 1090/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90388824.0000 - mae: 7074.4429 - val_loss: 65655928.0000 - val_mae: 6189.0737\n",
      "Epoch 1091/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90341728.0000 - mae: 7085.5425 - val_loss: 65487040.0000 - val_mae: 6167.7471\n",
      "Epoch 1092/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 90295736.0000 - mae: 7070.5908 - val_loss: 65570860.0000 - val_mae: 6185.6660\n",
      "Epoch 1093/1100\n",
      "102/102 [==============================] - 0s 39us/step - loss: 90250368.0000 - mae: 7082.4565 - val_loss: 65399920.0000 - val_mae: 6164.1260\n",
      "Epoch 1094/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90205840.0000 - mae: 7067.1655 - val_loss: 65484268.0000 - val_mae: 6181.9541\n",
      "Epoch 1095/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90161344.0000 - mae: 7079.5190 - val_loss: 65316640.0000 - val_mae: 6160.3618\n",
      "Epoch 1096/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90118072.0000 - mae: 7064.2866 - val_loss: 65401964.0000 - val_mae: 6178.2266\n",
      "Epoch 1097/1100\n",
      "102/102 [==============================] - 0s 49us/step - loss: 90074792.0000 - mae: 7076.7690 - val_loss: 65232272.0000 - val_mae: 6156.4331\n",
      "Epoch 1098/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 90031680.0000 - mae: 7061.2378 - val_loss: 65318200.0000 - val_mae: 6174.3013\n",
      "Epoch 1099/1100\n",
      "102/102 [==============================] - 0s 29us/step - loss: 89988368.0000 - mae: 7074.2881 - val_loss: 65150952.0000 - val_mae: 6152.2681\n",
      "Epoch 1100/1100\n",
      "102/102 [==============================] - 0s 20us/step - loss: 89944264.0000 - mae: 7058.1562 - val_loss: 65237316.0000 - val_mae: 6170.0684\n"
     ]
    }
   ],
   "source": [
    "# FITTING\n",
    "history = model.fit(train_data, train_targets, epochs=1100, batch_size=256, validation_data= (val_data, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
